{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from splinter import Browser\n",
    "from requests import Session\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from time import sleep\n",
    "\n",
    "import config\n",
    "\n",
    "from pyvirtualdisplay import Display\n",
    "\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium import webdriver\n",
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<firebase_admin.App at 0x11008d2b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the service account key JSON file contents\n",
    "cred = credentials.Certificate(config.firebase_file_path)\n",
    "# Initialize the app with a service account, granting admin privileges\n",
    "firebase_admin.initialize_app(cred, {\n",
    "    'databaseURL': config.databaseURL\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful 1st Attempt Login\n"
     ]
    }
   ],
   "source": [
    "# Start Browser\n",
    "driver = webdriver.Chrome(\"/usr/local/bin/chromedriver\")\n",
    "sleep(5)\n",
    "\n",
    "# Navigate to login page\n",
    "driver.get(\"https://www.etsy.com/signin\")\n",
    "sleep(5)\n",
    "\n",
    "try:\n",
    "    # Populate sign in fields\n",
    "    emailElem = driver.find_element_by_id(\"join_neu_email_field\")\n",
    "    emailElem.send_keys(config.email_address)\n",
    "\n",
    "    sleep(5)\n",
    "\n",
    "    passwordElem = driver.find_element_by_id(\"join_neu_password_field\")\n",
    "    passwordElem.send_keys(config.etsy_password)\n",
    "\n",
    "    sleep(5)\n",
    "\n",
    "    # Submit sign in information\n",
    "    passwordElem.submit()\n",
    "\n",
    "\n",
    "    print(\"Successful 1st Attempt Login\")\n",
    "    sleep(5)\n",
    "\n",
    "\n",
    "# If first login attempt is unsuccessful, refresh the page and make 2nd attempt.\n",
    "except:\n",
    "    # Navigate to login page\n",
    "    driver.get(\"https://www.etsy.com/signin\")\n",
    "    sleep(5)\n",
    "\n",
    "    # Populate sign in fields\n",
    "    emailElem = driver.find_element_by_id(\"join_neu_email_field\")\n",
    "    emailElem.send_keys(config.email_address)\n",
    "    sleep(5)\n",
    "\n",
    "    passwordElem = driver.find_element_by_id(\"join_neu_password_field\")\n",
    "    passwordElem.send_keys(config.etsy_password)\n",
    "    sleep(5)\n",
    "\n",
    "    # Submit sign in information\n",
    "    passwordElem.submit()\n",
    "    sleep(5)\n",
    "\n",
    "  \n",
    "    print(\"Successful 2nd Attempt Login\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "yesterday = date.today() - timedelta(days=1)\n",
    "yesterday_year = yesterday.strftime(\"%Y\")\n",
    "\n",
    "# ----------------- CSV DOWNLOADS ------------------#\n",
    "try:\n",
    "    # # Scrape - Download CSV Files\n",
    "    # Navigate to download page\n",
    "    driver.get(\"https://www.etsy.com/your/shops/jetchcreations/download\")\n",
    "    # Select options from dropdown lists & submit to begin download\n",
    "    # After download the page will refresh to prevent system notifications\n",
    "    \n",
    "    select = Select(driver.find_element_by_id(\"filter-csv-type\"))\n",
    "    select.select_by_value(\"order-level\")\n",
    "\n",
    "    select = Select(driver.find_element_by_id(\"filter-year\"))\n",
    "    select.select_by_value(yesterday_year)\n",
    "\n",
    "    button = driver.find_element_by_id(\"order-csv-form\")\n",
    "    button.submit()\n",
    "except:\n",
    "    print(\"error downloading csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sleep(5)\n",
    "try:\n",
    "    # Read in CSVs to dataframes\n",
    "    sold_orders_file_path = (\n",
    "        f\"/Users/jessicaetchechury/Downloads/EtsySoldOrders{yesterday_year}.csv\"\n",
    "    )\n",
    "    sold_orders_df = pd.read_csv(sold_orders_file_path)\n",
    "    # Convert data types to string\n",
    "    sold_orders_df = sold_orders_df.applymap(str)\n",
    "    \n",
    "except:\n",
    "    print(\"error reading csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sold_orders_df2 = sold_orders_df.rename(\n",
    "        columns={\n",
    "            \"Sale Date\": \"orderDate\",\n",
    "            \"Order ID\": \"orderID\",\n",
    "            \"Buyer User ID\": \"buyerID\",\n",
    "            \"First Name\": \"firstName\",\n",
    "            \"Last Name\": \"lastName\",\n",
    "            \"Date Shipped\": \"dateShipped\",\n",
    "            \"Street 1\": \"street1\",\n",
    "            \"Street 2\": \"street2\",\n",
    "            \"Ship City\": \"city\",\n",
    "            \"Ship State\": \"state\",\n",
    "            \"Ship Zipcode\": \"zipCode\",\n",
    "            \"Ship Country\": \"country\",\n",
    "            \"Order Value\": \"orderValue\",\n",
    "            \"Coupon Code\": \"couponCode\",\n",
    "            \"Coupon Details\": \"details\",\n",
    "            \"Discount Amount\": \"discountAmount\",\n",
    "            \"Shipping Discount\": \"shippingDiscount\",\n",
    "            \"Shipping\": \"shipping\",\n",
    "            \"Sales Tax\": \"salesTax\",\n",
    "            \"Order Total\": \"orderTotal\",\n",
    "            \"Card Processing Fees\": \"fees\",\n",
    "            \"Order Net\": \"orderNet\",\n",
    "            \"Adjusted Order Total\": \"adjustedTotal\",\n",
    "            \"Adjusted Card Processing Fees\": \"adjustedFees\",\n",
    "            \"Adjusted Net Order Amount\": \"adjustedNet\",\n",
    "            \"Order Type\": \"orderType\",\n",
    "            \"Payment Type\": \"paymentType\",\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_shipped_df = sold_orders_df2[['orderID','dateShipped']]\n",
    "#delete rows that contain NaN/null - only want to import complete records\n",
    "orders_shipped_df2 = orders_shipped_df[~orders_shipped_df.dateShipped.str.contains(\"nan\")]\n",
    "orders_shipped_df3 = orders_shipped_df2.applymap(str)\n",
    "orders_shipped_df3.fillna(\"\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that records for the day have not already been added\n",
    "# Do the following if the dataframe is not empty\n",
    "if orders_shipped_df3.empty == False:\n",
    "    fb_db = \"order_shipped.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "#         data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "#         data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase order_shipped\")\n",
    "        print(\"***ERROR- Acess Firebase order_shipped\")\n",
    "        \n",
    "    df_tups = [(item.orderID, item.dateShipped) for index, item in df_fb.iterrows()]\n",
    "    \n",
    "    \n",
    "    ref = db.reference('order_shipped')\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    \n",
    "    # New record count\n",
    "    count=0\n",
    "    \n",
    "    for index, item in orders_shipped_df3.iterrows():\n",
    "        \n",
    "        # Create tuples from local df        \n",
    "        var_o=item.orderID, item.dateShipped\n",
    "        \n",
    "        if var_o not in df_tups:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "\n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "\n",
    "            items=item.values.tolist()\n",
    "\n",
    "            new_val= \", \".join( repr(e) for e in items ) \n",
    "\n",
    "            new_val2=new_val.replace(\"'\",\"\")\n",
    "\n",
    "#             txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/order_shipped.txt\",\"a\")\n",
    "#             txt_file.write(f\"\\n{new_val2}\") \n",
    "#             txt_file.close()            \n",
    "            \n",
    "        else:\n",
    "            pass        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Complete- orders_shipped_df\n",
      "Firebase- 0 records added to order_shipped\n"
     ]
    }
   ],
   "source": [
    "yesterday_full_date = yesterday.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# # Order_shipped DF\n",
    "\n",
    "orders_shipped_df = sold_orders_df2[[\"orderID\", \"dateShipped\"]]\n",
    "# delete rows that contain NaN/null - only want to import complete records\n",
    "orders_shipped_df2 = orders_shipped_df[orders_shipped_df.dateShipped.str.contains(\"nan\")]\n",
    "orders_shipped_df3 = orders_shipped_df2.applymap(str)\n",
    "orders_shipped_df3.fillna(\"\", inplace=True)\n",
    "\n",
    "print(\"DF Complete- orders_shipped_df\")\n",
    "\n",
    "\n",
    "\n",
    "# Check that records for the day have not already been added\n",
    "# Do the following if the dataframe is not empty\n",
    "if orders_shipped_df3.empty == False:\n",
    "    fb_db = \"order_shipped.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient=\"columns\")\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        print(\"***ERROR- Acess Firebase order_shipped\")\n",
    "\n",
    "    df_tups = [(item.orderID, item.dateShipped) for index, item in df_fb.iterrows()]\n",
    "\n",
    "    ref = db.reference(\"order_shipped\")\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "\n",
    "    # New record count\n",
    "    count = 0\n",
    "\n",
    "    for index, item in orders_shipped_df3.iterrows():\n",
    "\n",
    "        # Create tuples from local df\n",
    "        var_o = item.orderID, item.dateShipped\n",
    "\n",
    "        if var_o not in df_tups:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict())\n",
    "\n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "\n",
    "            items = item.values.tolist()\n",
    "\n",
    "            new_val = \", \".join(repr(e) for e in items)\n",
    "\n",
    "            new_val2 = new_val.replace(\"'\", \"\")\n",
    "\n",
    "            txt_file = open(\n",
    "                \"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/order_shipped.txt\",\n",
    "                \"a\",\n",
    "            )\n",
    "            txt_file.write(f\"\\n{new_val2}\")\n",
    "            txt_file.close()\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    print(f\"Firebase- {count} records added to order_shipped\")\n",
    "\n",
    "\n",
    "else:\n",
    "\n",
    "    print(\"DF EMPTY- orders_shipped_df3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Complete- buyer_contact\n",
      "Open orders scraped\n",
      "DF Complete- orders_df_temp2\n",
      "DF Complete- open_orders_df\n"
     ]
    }
   ],
   "source": [
    "# ----------------- OPEN ORDERS ------------------#\n",
    "\n",
    "# # Scrape - Open Orders\n",
    "# Create lists to hold query information\n",
    "open_order_id = []\n",
    "open_order_query_urls = []\n",
    "ship_by_date = []\n",
    "order_time = []\n",
    "\n",
    "email = []\n",
    "orderID = []\n",
    "buyer = []\n",
    "\n",
    "# Navigate to page\n",
    "open_order_page_url = \"https://www.etsy.com/your/orders/sold?ref=seller-platform-mcnav\"\n",
    "\n",
    "driver.get(open_order_page_url)\n",
    "sleep(2)\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# Gather buyer contact information\n",
    "try:\n",
    "    for each in soup.find_all(\"div\", class_=\"panel-body-row\"):\n",
    "        for item in each:\n",
    "            split_details = list(item.stripped_strings)\n",
    "            if \"View user profile\" in split_details:\n",
    "                # Find index of generic item in list\n",
    "                target_index = split_details.index(\"#\")\n",
    "                # Create new shorter list and then extract information needed\n",
    "                newList = split_details[: target_index + 2]\n",
    "                orderNo = newList[-1]\n",
    "                orderID.append(orderNo)\n",
    "                buyerName = newList[0]\n",
    "                buyer.append(buyerName)\n",
    "                email_address = newList[-3]\n",
    "                email.append(email_address)\n",
    "\n",
    "    buyer_contact = pd.DataFrame({\"orderID\": orderID, \"Name\": buyer, \"email\": email})\n",
    "\n",
    "    # Convert all objects in dataframe to strings and fill N/A with whitespace\n",
    "    buyer_contact = buyer_contact.applymap(str)\n",
    "    buyer_contact.fillna(\"\", inplace=True)\n",
    "\n",
    "    print(\"DF Complete- buyer_contact\")\n",
    "\n",
    "    # Locate html to scrape\n",
    "    open_orders_page = soup.find_all(\"div\", class_=\"col-xs-12 col-md-8\")\n",
    "\n",
    "    for orders in open_orders_page:\n",
    "        customer_name = orders.find(\"span\", id=\"unsanitize\")\n",
    "\n",
    "    open_orders_page = soup.find_all(\n",
    "        \"h2\", class_=\"col-xs-5 col-md-12 text-body-smaller text-gray\"\n",
    "    )\n",
    "\n",
    "    # Loop through html to find order IDs to create URLS\n",
    "    for orders in open_orders_page:\n",
    "        open_order_url = orders.find(\"a\", class_=\"text-gray\")[\"href\"]\n",
    "\n",
    "        open_order_id_value = open_order_url.replace(\n",
    "            \"/your/orders/sold?ref=seller-platform-mcnav&order_id=\", \"\"\n",
    "        ).replace(\"/your/orders/sold?order_id=\", \"\")\n",
    "        open_order_id.append(open_order_id_value)\n",
    "\n",
    "        open_order_url = \"https://www.etsy.com\" + open_order_url\n",
    "        open_order_query_urls.append(open_order_url)\n",
    "\n",
    "    # Loop through open order pages and append target info to lists\n",
    "    for url in open_order_query_urls:\n",
    "\n",
    "        driver.get(url)\n",
    "        sleep(2)\n",
    "\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html, \"html.parser\")\n",
    "        tomorrow = date.today() + timedelta(days=1)\n",
    "\n",
    "        ship_by_date_values = (\n",
    "            soup.find(\n",
    "                \"div\",\n",
    "                class_=\"flag-img flag-img-right no-wrap text-right vertical-align-bottom hide-xs hide-sm\",\n",
    "            )\n",
    "            .find(\"div\", class_=\"strong\")\n",
    "            .text\n",
    "        )\n",
    "\n",
    "        ship_by_date_values = ship_by_date_values.replace(\"Ship by \", \"\")\n",
    "\n",
    "        def validate(date_text):\n",
    "            try:\n",
    "                datetime.strptime(ship_by_date_values, \"%b %d, %Y\")\n",
    "                return True\n",
    "            except ValueError:\n",
    "                return False\n",
    "\n",
    "        if validate(ship_by_date_values) == True:\n",
    "            d = datetime.strptime(ship_by_date_values, \"%b %d, %Y\")\n",
    "        elif ship_by_date_values == \"today\":\n",
    "            d = today\n",
    "        else:\n",
    "            d = tomorrow\n",
    "\n",
    "        ship_by_date_values = d.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        ship_by_date.append(ship_by_date_values)\n",
    "\n",
    "        order_date_values = (\n",
    "            soup.find(\n",
    "                \"div\",\n",
    "                class_=\"flag-img flag-img-right no-wrap text-right vertical-align-bottom hide-xs hide-sm\",\n",
    "            )\n",
    "            .find(\"div\", class_=\"text-body-smaller mt-xs-1\")\n",
    "            .text\n",
    "        )\n",
    "\n",
    "        order_date_values = order_date_values.replace(\"Ordered \", \"\")\n",
    "        order_date_values = order_date_values.strip(\" \")\n",
    "        d = datetime.strptime(order_date_values, \"%I:%M%p, %a, %b %d, %Y\")\n",
    "        order_date_values = d.strftime(\"%m%d%y\")\n",
    "        order_time_values = d.strftime(\"%H:%M\")\n",
    "        order_time.append(order_time_values)\n",
    "\n",
    "\n",
    "    print(\"Open orders scraped\")\n",
    "\n",
    "    orders_df_temp2 = pd.DataFrame(\n",
    "        {\n",
    "            \"orderID\": open_order_id,\n",
    "            \"orderURL\": open_order_query_urls,\n",
    "            \"shipByDate\": ship_by_date,\n",
    "            \"orderTime\": order_time,\n",
    "        }\n",
    "    )\n",
    "    orders_df_temp2[\"record_date\"] = yesterday\n",
    "\n",
    "    # Turn all objects in dataframe to strings and replace NaN with whitespace\n",
    "    orders_df_temp2 = orders_df_temp2.applymap(str)\n",
    "    orders_df_temp2.fillna(\"\", inplace=True)\n",
    "\n",
    "    print(\"DF Complete- orders_df_temp2\")\n",
    "\n",
    "    open_orders_df = pd.merge(orders_df_temp2, buyer_contact, on=\"orderID\", how=\"inner\")\n",
    "\n",
    "    print(\"DF Complete- open_orders_df\")\n",
    "\n",
    "except:\n",
    "\n",
    "    print(\"***ERROR: OPEN ORDERS SCRAPE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Complete- orders_df\n"
     ]
    }
   ],
   "source": [
    "## Orders DF\n",
    "\n",
    "# Create data frame from CSV\n",
    "orders_df_temp1 = sold_orders_df2[[\"orderID\", \"orderDate\", \"buyerID\"]]\n",
    "\n",
    "# Only return open orders\n",
    "orders_df = pd.merge(orders_df_temp1, orders_df_temp2, on=\"orderID\", how=\"outer\")\n",
    "\n",
    "orders_df = orders_df[\n",
    "    [\"orderID\", \"orderDate\", \"orderTime\", \"shipByDate\", \"buyerID\", \"orderURL\"]\n",
    "]\n",
    "\n",
    "orders_df[\"orderDate\"] = pd.to_datetime(\n",
    "    orders_df[\"orderDate\"], format=\"%m/%d/%y\", errors=\"coerce\"\n",
    ").dt.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "orders_df = orders_df.applymap(str)\n",
    "orders_df.fillna(\"\", inplace=True)\n",
    "\n",
    "print(\"DF Complete- orders_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Firebase- 0 records added to orders\n"
     ]
    }
   ],
   "source": [
    "# Check that records for the day have not already been added\n",
    "# Do the following if the dataframe is not empty\n",
    "if orders_df.empty == False:\n",
    "    fb_db = \"orders.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient=\"columns\")\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        print(\"***ERROR- Acess Firebase orders\")\n",
    "\n",
    "    orderIDs_ = df_fb.orderID.values\n",
    "\n",
    "    ref = db.reference(\"orders\")\n",
    "\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    # New record count\n",
    "    count = 0\n",
    "\n",
    "    for index, item in orders_df.iterrows():\n",
    "        if item.orderID not in orderIDs_:\n",
    "            # push\n",
    "            ref.push(item.to_dict())\n",
    "\n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "\n",
    "            items = item.values.tolist()\n",
    "\n",
    "            new_val = \", \".join(repr(e) for e in items)\n",
    "\n",
    "            new_val2 = new_val.replace(\"'\", \"\")\n",
    "\n",
    "            txt_file = open(\n",
    "                \"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/orders.txt\",\n",
    "                \"a\",\n",
    "            )\n",
    "            txt_file.write(f\"\\n{new_val2}\")\n",
    "            txt_file.close()\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "    print(f\"Firebase- {count} records added to orders\")\n",
    "\n",
    "\n",
    "else:\n",
    "    print(\"DF EMPTY- orders_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DF Complete- buyer_info_df\n",
      "Firebase- 0 records added to buyers\n"
     ]
    }
   ],
   "source": [
    "buyers_df = sold_orders_df2[[\"orderID\", \"buyerID\", \"firstName\", \"lastName\"]]\n",
    "\n",
    "\n",
    "buyer_info_df = pd.merge(buyers_df, buyer_contact, on=\"orderID\", how=\"outer\")\n",
    "buyer_info_df = buyer_info_df.drop([\"Name\"], axis=1)\n",
    "buyer_info_df\n",
    "\n",
    "\n",
    "buyer_info_df[\"record_date\"] = yesterday_full_date\n",
    "\n",
    "buyer_info_df = buyer_info_df.applymap(str)\n",
    "buyer_info_df.fillna(\"\", inplace=True)\n",
    "\n",
    "\n",
    "print(\"DF Complete- buyer_info_df\")\n",
    "\n",
    "# Check that records for the day have not already been added\n",
    "# Do the following if the dataframe is not empty\n",
    "if buyer_info_df.empty == False:\n",
    "    fb_db = \"buyers.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient=\"columns\")\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "       \n",
    "        print(\"***ERROR- Acess Firebase buyer_info_df\")\n",
    "\n",
    "    df_tups = [(item.buyerID, item.orderID) for index, item in df_fb.iterrows()]\n",
    "\n",
    "    ref = db.reference(\"buyers\")\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "\n",
    "    # New record count\n",
    "    count = 0\n",
    "\n",
    "    for index, item in buyer_info_df.iterrows():\n",
    "\n",
    "        # Create tuples from local df\n",
    "        var_o = item.buyerID, item.orderID\n",
    "\n",
    "        if var_o not in df_tups:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict())\n",
    "\n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "\n",
    "            items = item.values.tolist()\n",
    "\n",
    "            new_val = \", \".join(repr(e) for e in items)\n",
    "\n",
    "            new_val2 = new_val.replace(\"'\", \"\")\n",
    "\n",
    "            txt_file = open(\n",
    "                \"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/buyers.txt\",\n",
    "                \"a\",\n",
    "            )\n",
    "            txt_file.write(f\"\\n{new_val2}\")\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "   \n",
    "    print(f\"Firebase- {count} records added to buyers\")\n",
    "\n",
    "\n",
    "else:\n",
    "   \n",
    "    print(\"DF EMPTY- buyer_info_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(sold_orders_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
