{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from splinter import Browser\n",
    "from requests import Session\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import re\n",
    "import json\n",
    "from pprint import pprint\n",
    "\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from time import sleep\n",
    "\n",
    "import config\n",
    "\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium import webdriver\n",
    "\n",
    "import firebase_admin\n",
    "from firebase_admin import credentials\n",
    "from firebase_admin import db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<firebase_admin.App at 0x1035e0128>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch the service account key JSON file contents\n",
    "cred = credentials.Certificate(config.firebase_file_path)\n",
    "# Initialize the app with a service account, granting admin privileges\n",
    "firebase_admin.initialize_app(cred, {\n",
    "    'databaseURL': config.databaseURL\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time variables\n",
    "now = datetime.now()\n",
    "year=now.strftime('%Y')\n",
    "today=date.today()\n",
    "today_full_date=today.strftime('%Y-%m-%d')\n",
    "yesterday = date.today() - timedelta(days=1)\n",
    "yesterday_year=yesterday.strftime('%Y')\n",
    "yesterday_month_padding=yesterday.strftime('%m')\n",
    "yesterday_month_no_padding=yesterday.strftime('%-m')\n",
    "yesterday_full_date=yesterday.strftime('%Y-%m-%d')\n",
    "yesterday_month_day=yesterday.strftime('%m_%d')\n",
    "month_day_today=now.strftime('%m_%d')\n",
    "month_day_yesterday=yesterday.strftime('%m_%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"w+\")\n",
    "data_collection_log.write(\"----------------------------------------------\")\n",
    "data_collection_log.write(f\"\\nDATA COLLECTION LOG FOR {yesterday_full_date}\")\n",
    "data_collection_log.write(\"\\n----------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init Browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful 1st Attempt Login\n"
     ]
    }
   ],
   "source": [
    "# Start Browser\n",
    "driver = webdriver.Chrome('/usr/local/bin/chromedriver')\n",
    "sleep(5)\n",
    "\n",
    "# Navigate to login page\n",
    "driver.get('https://www.etsy.com/signin')\n",
    "sleep(5)\n",
    "\n",
    "try:\n",
    "    # Populate sign in fields\n",
    "    emailElem = driver.find_element_by_id('join_neu_email_field')\n",
    "    emailElem.send_keys(config.email_address)\n",
    "    \n",
    "    sleep(5)\n",
    "\n",
    "    passwordElem = driver.find_element_by_id('join_neu_password_field')\n",
    "    passwordElem.send_keys(config.etsy_password)\n",
    "    \n",
    "    sleep(5)\n",
    "\n",
    "    # Submit sign in information\n",
    "    passwordElem.submit()\n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Successful 1st Attempt Login\")\n",
    "    print(\"Successful 1st Attempt Login\")\n",
    "    sleep(5)\n",
    "    \n",
    "\n",
    "# If first login attempt is unsuccessful, refresh the page and make 2nd attempt.\n",
    "except:\n",
    "    # Navigate to login page\n",
    "    driver.get('https://www.etsy.com/signin')\n",
    "    sleep(5)\n",
    "    \n",
    "    # Populate sign in fields\n",
    "    emailElem = driver.find_element_by_id('join_neu_email_field')\n",
    "    emailElem.send_keys(config.email_address)\n",
    "    sleep(5)\n",
    "\n",
    "    passwordElem = driver.find_element_by_id('join_neu_password_field')\n",
    "    passwordElem.send_keys(config.etsy_password)\n",
    "    sleep(5)\n",
    "\n",
    "    # Submit sign in information\n",
    "    passwordElem.submit()\n",
    "    sleep(5)\n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} ***SUCCESSFUL 2ND ATTEMPT LOGIN\")\n",
    "    print(\"Successful 2nd Attempt Login\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape Favorites & Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.etsy.com/your/shops/me/dashboard?ref=mcpa'\n",
    "\n",
    "driver.get(url)\n",
    "sleep(2)\n",
    "html=driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Button click count\n",
    "r = 0\n",
    "\n",
    "# Click button to reveal recent activity in activity panel \n",
    "while r<5:\n",
    "    try:\n",
    "        elm = driver.find_element_by_xpath('//*[@id=\"recent-activity-content-region\"]/div/div/span/button')\n",
    "        actions = ActionChains(driver)\n",
    "        actions.move_to_element(elm).click().perform()\n",
    "        sleep(2)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "        sleep(1)\n",
    "        r += 1\n",
    "        \n",
    "    except:\n",
    "        break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------- FAVORITES AND REVIEWS SCRAPE ------------------#\n",
    "#Re-read HTML on page to included information revealed \n",
    "html=driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Find html in activity panel\n",
    "activity_panel = soup.find('div',class_='activity-stream')\n",
    "\n",
    "# Scrape favorites and reviews information from activity panel and append to lists\n",
    "void=[]\n",
    "people=[]\n",
    "listing=[]\n",
    "date_liked=[]\n",
    "\n",
    "reviewer=[]\n",
    "date_reviewed=[]\n",
    "\n",
    "try:\n",
    "    # Find unorder lists in activity panel\n",
    "    for ul in activity_panel.find_all('ul'):\n",
    "        # Find lists in unorder lists \n",
    "        for li in ul.find_all('li'):\n",
    "            \n",
    "            # Split text in list\n",
    "            for item in li:\n",
    "                split_details = list(item.stripped_strings)\n",
    "\n",
    "                # Only pull information from reviews\n",
    "                if 'left a review on your listing:' in split_details:\n",
    "                    # Find shopper URL and append to list\n",
    "                    link=item.find(\"a\", href=re.compile('^https://www.etsy.com/people/'))\n",
    "                    reviewer.append(link['href'])\n",
    "                    \n",
    "                    # Find date and append to list\n",
    "                    date_format='%Y-%m-%d'\n",
    "                    date_of_favorite=item.find('span',class_='wt-text-caption').text\n",
    "\n",
    "                    if date_of_favorite=='1 day ago':\n",
    "                        date_value = date.today() - timedelta(days=1)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_reviewed.append(date_value)\n",
    "                    elif date_of_favorite=='2 days ago':\n",
    "                        date_value = date.today() - timedelta(days=2)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_reviewed.append(date_value)\n",
    "                    elif date_of_favorite=='3 days ago':\n",
    "                        date_value = date.today() - timedelta(days=3)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_reviewed.append(date_value)\n",
    "                    elif date_of_favorite=='4 days ago':\n",
    "                        date_value = date.today() - timedelta(days=4)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_reviewed.append(date_value)\n",
    "                    elif date_of_favorite=='5 days ago':\n",
    "                        date_value = date.today() - timedelta(days=5)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_reviewed.append(date_value)\n",
    "                    elif date_of_favorite=='6 days ago':\n",
    "                        date_value = date.today() - timedelta(days=6)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_reviewed.append(date_value)\n",
    "                    elif date_of_favorite=='7 days ago':\n",
    "                        date_value = date.today() - timedelta(days=7)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_reviewed.append(date_value)\n",
    "                    elif 'hours ago' in date_of_favorite:\n",
    "                        date_value = yesterday_full_date\n",
    "                        date_reviewed.append(date_value)\n",
    "                    elif 'hour ago' in date_of_favorite:\n",
    "                        date_value= yesterday_full_date\n",
    "                        date_reviewed.append(date_value)\n",
    "                    else:\n",
    "                        date_value=datetime.strptime(date_of_favorite,\n",
    "                                    '%b %d').strftime(yesterday_year+'-%m-%d')\n",
    "                        date_reviewed.append(date_value)\n",
    "\n",
    "                if 'left a review on your listing' in split_details:\n",
    "                    # Find shopper URL and append to list\n",
    "                    link=item.find(\"a\", href=re.compile('^https://www.etsy.com/people/'))\n",
    "                    reviewer.append(link['href'])\n",
    "                    \n",
    "                    # Find date and append to list\n",
    "                    date_format='%Y-%m-%d'\n",
    "                    date_of_favorite=item.find('span',class_='wt-text-caption').text\n",
    "\n",
    "                    if date_of_favorite=='1 day ago':\n",
    "                        date_value = date.today() - timedelta(days=1)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_reviewed.append(date_value)\n",
    "                    elif date_of_favorite=='2 days ago':\n",
    "                        date_value = date.today() - timedelta(days=2)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_reviewed.append(date_value)\n",
    "                    elif date_of_favorite=='3 days ago':\n",
    "                        date_value = date.today() - timedelta(days=3)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_reviewed.append(date_value)\n",
    "                    elif date_of_favorite=='4 days ago':\n",
    "                        date_value = date.today() - timedelta(days=4)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_reviewed.append(date_value)\n",
    "                    elif date_of_favorite=='5 days ago':\n",
    "                        date_value = date.today() - timedelta(days=5)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_reviewed.append(date_value)\n",
    "                    elif date_of_favorite=='6 days ago':\n",
    "                        date_value = date.today() - timedelta(days=6)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_reviewed.append(date_value)\n",
    "                    elif date_of_favorite=='7 days ago':\n",
    "                        date_value = date.today() - timedelta(days=7)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_reviewed.append(date_value)\n",
    "                    elif 'hours ago' in date_of_favorite:\n",
    "                        date_value = yesterday_full_date\n",
    "                        date_reviewed.append(date_value)\n",
    "                    elif 'hour ago' in date_of_favorite:\n",
    "                        date_value= yesterday_full_date\n",
    "                        date_reviewed.append(date_value)\n",
    "                    else:\n",
    "                        date_value=datetime.strptime(date_of_favorite,\n",
    "                                    '%b %d').strftime(yesterday_year+'-%m-%d')\n",
    "                        date_reviewed.append(date_value)\n",
    "                    \n",
    "\n",
    "                # Only pull information from favorites\n",
    "                if 'favorited your item:' in split_details:\n",
    "\n",
    "                    # Find shopper URL and append to list\n",
    "                    link=item.find(\"a\", href=re.compile('^https://www.etsy.com/people/'))\n",
    "                    people.append(link['href'])\n",
    "\n",
    "                    # Find listing ID URL and append to list\n",
    "                    link=item.find(\"a\", href=re.compile('^https://www.etsy.com/listing/'))\n",
    "                    listing.append(link['href'])\n",
    "                    \n",
    "                    # Find date and append to list\n",
    "                    date_format='%Y-%m-%d'\n",
    "                    date_of_favorite=item.find('span',class_='wt-text-caption').text\n",
    "\n",
    "                    if date_of_favorite=='1 day ago':\n",
    "                        date_value = date.today() - timedelta(days=1)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_liked.append(date_value)\n",
    "                    elif date_of_favorite=='2 days ago':\n",
    "                        date_value = date.today() - timedelta(days=2)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_liked.append(date_value)\n",
    "                    elif date_of_favorite=='3 days ago':\n",
    "                        date_value = date.today() - timedelta(days=3)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_liked.append(date_value)\n",
    "                    elif date_of_favorite=='4 days ago':\n",
    "                        date_value = date.today() - timedelta(days=4)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_liked.append(date_value)\n",
    "                    elif date_of_favorite=='5 days ago':\n",
    "                        date_value = date.today() - timedelta(days=5)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_liked.append(date_value)\n",
    "                    elif date_of_favorite=='6 days ago':\n",
    "                        date_value = date.today() - timedelta(days=6)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_liked.append(date_value)\n",
    "                    elif date_of_favorite=='7 days ago':\n",
    "                        date_value = date.today() - timedelta(days=7)\n",
    "                        date_value=date_value.strftime(date_format)\n",
    "                        date_liked.append(date_value)\n",
    "                    elif 'hours ago' in date_of_favorite:\n",
    "                        date_value = yesterday_full_date\n",
    "                        date_liked.append(date_value)\n",
    "                    elif 'hour ago' in date_of_favorite:\n",
    "                        date_value= yesterday_full_date\n",
    "                        date_liked.append(date_value)\n",
    "                    elif 'minutes ago' in date_of_favorite:\n",
    "                        date_value= yesterday_full_date\n",
    "                        date_liked.append(date_value)\n",
    "                    else:\n",
    "                        date_value=datetime.strptime(date_of_favorite,\n",
    "                                    '%b %d').strftime(yesterday_year+'-%m-%d')\n",
    "                        date_liked.append(date_value)\n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Favorites and reviews scraped\")\n",
    "    print(\"Favorites and reviews scraped\")   \n",
    "    \n",
    "except:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} ***ERROR: Favorites and reviews scrape\")\n",
    "    print(\"***ERROR: Favorites and reviews scrape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------- FAVORITES ------------------#\n",
    "\n",
    "# Create temporary dataframe\n",
    "favorites_temp=pd.DataFrame({'listingLink':listing,\n",
    "                       'buyerLink':people,\n",
    "                       'dateLiked':date_liked})\n",
    "\n",
    "# Turn all objects in dataframe to strings\n",
    "favorites_temp = favorites_temp.applymap(str)\n",
    "\n",
    "# Do the following if the dataframe is not empty\n",
    "if favorites_temp.empty == False:\n",
    "    \n",
    "    # Extract listingID from listing link\n",
    "    new = favorites_temp[\"listingLink\"].str.split(\"/\", expand = True) \n",
    "    favorites_temp['listingID']=new[4]\n",
    "\n",
    "    # Extract buyerID from buyer link\n",
    "    new2= favorites_temp[\"buyerLink\"].str.split(\"/\", expand = True) \n",
    "    favorites_temp['buyerID']=new2[4]\n",
    "    new3= favorites_temp[\"buyerID\"].str.split(\"?\",n=1, expand = True) \n",
    "    favorites_temp['buyerID']=new3[0]\n",
    "    \n",
    "    # Create new df with clean data\n",
    "    favorites=favorites_temp[['listingID','buyerID','dateLiked']]\n",
    "    \n",
    "    # Fill n/a with whitespace\n",
    "    favorites.fillna(\"\", inplace=True)\n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF Complete- favorites\")\n",
    "    print(\"DF Complete- favorites\")\n",
    "    # Append new favorites to database\n",
    "    \n",
    "    # Call firebase database\n",
    "    fav_db = \"favorites.json\"\n",
    "    r = requests.get(config.databaseURL + fav_db)\n",
    "    r = r.json()\n",
    "    \n",
    "    # If database is not empty create df\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    \n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR: Access Firebase Favorites\")\n",
    "        print(\"***ERROR: Access Firebase Favorites\")\n",
    "        \n",
    "    # Create tuples of data that already exisits in database\n",
    "    favTuples = [(item.buyerID, item.dateLiked, item.listingID) for index, item in df_fb.iterrows()]\n",
    "\n",
    "    \n",
    "    # Assign variable to database where information will be pushed\n",
    "    ref = db.reference('favorites')\n",
    "    \n",
    "    # Count of items pushed to database\n",
    "    count=0\n",
    "    \n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    for index, item in favorites.iterrows():\n",
    "        # Create tuples from local df\n",
    "        var_o=item.buyerID,item.dateLiked,item.listingID\n",
    "        \n",
    "        if var_o not in favTuples:\n",
    "            \n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "            \n",
    "            # Add to new favorites count\n",
    "            count += 1\n",
    "            \n",
    "            # Convert tuples to string and place them in a text file\n",
    "            tup=str(var_o).replace(\"(\",\"\")\n",
    "            str_tup=tup.replace(\")\",\"\")\n",
    "            str_tup2=str_tup.replace(\"'\",\"\")\n",
    "            \n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/favorites.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{str_tup2}\")            \n",
    "\n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "            \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to Favorites\")\n",
    "    print(f\"Firebase- {count} records added to Favorites\")\n",
    "    \n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- Favorites\")\n",
    "    print(\"DF EMPTY- Favorites\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------- REVIEWS ------------------#\n",
    "# Create temporary dataframe\n",
    "reviews_temp=pd.DataFrame({'reviewer':reviewer,\n",
    "                          'date_reviewed':date_reviewed})\n",
    "\n",
    "# Turn all objects in dataframe to strings\n",
    "reviews_temp = reviews_temp.applymap(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the following if the dataframe is not empty\n",
    "if reviews_temp.empty == False:\n",
    "    \n",
    "    # Extract buyerID from buyer link\n",
    "    new2= reviews_temp[\"reviewer\"].str.split(\"/\", expand = True) \n",
    "    reviews_temp['buyerID']=new2[4]\n",
    "    new3= reviews_temp[\"buyerID\"].str.split(\"?\",n=1, expand = True) \n",
    "    reviews_temp['buyerID']=new3[0]\n",
    "    \n",
    "    # Create new df with clean data\n",
    "    reviews=reviews_temp[['buyerID','date_reviewed']]\n",
    "    \n",
    "    print(reviews)\n",
    "    # Fill n/a with whitespace\n",
    "    reviews.fillna(\"\", inplace=True)\n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF Complete- reviews\")\n",
    "    print(\"DF Complete- reviews\")\n",
    "    ## Append new reviews to database\n",
    "    \n",
    "    # Call firebase database    \n",
    "    reviews_db = \"reviews.json\"\n",
    "    r = requests.get(config.databaseURL + reviews_db)\n",
    "    r = r.json()\n",
    "\n",
    "    # If database is not empty create df\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR: Access Firebase Reviews\")\n",
    "        print(\"ERROR: Access Firebase Reviews\")\n",
    "\n",
    "    # Create tuples of data that already exisits in database\n",
    "    revTuples = [(item.buyerID, item.date_reviewed) for index, item in df_fb.iterrows()]\n",
    "\n",
    "    # Assign variable to database where information will be pushed\n",
    "    ref = db.reference('reviews')\n",
    "    reviews.fillna(\"\", inplace=True)\n",
    "    \n",
    "    # Count of items pushed to database\n",
    "    count=0\n",
    "    \n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    for index, item in reviews.iterrows():\n",
    "        \n",
    "        # Create tuples from local df\n",
    "        var_o=item.buyerID, item.date_reviewed\n",
    "        \n",
    "        if var_o not in revTuples:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "            \n",
    "            # Add to new favorites count            \n",
    "            count += 1\n",
    "            \n",
    "            # Convert tuples to string and place them in a text file\n",
    "            tup=str(var_o).replace(\"(\",\"\")\n",
    "            str_tup=tup.replace(\")\",\"\")\n",
    "            str_tup2=str_tup.replace(\"'\",\"\")\n",
    "            \n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/reviews.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{str_tup2}\")  \n",
    "            \n",
    "        else:\n",
    "            pass            \n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to Reviews\")\n",
    "    print(f\"Firebase- {count} records added to Reviews\")\n",
    "    \n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- Reviews\")\n",
    "    print(\"DF EMPTY- Reviews\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------- REVIEWS2 ------------------#\n",
    "# Scrape additional review information\n",
    "url='https://www.etsy.com/your/orders/sold/completed?ref=seller-platform-mcnav&page=1'\n",
    "\n",
    "driver.get(url)\n",
    "sleep(2)\n",
    "html=driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "email=[]\n",
    "orderID=[]\n",
    "buyer=[]\n",
    "\n",
    "try:\n",
    "    for each in soup.find_all('div',class_='panel-body-row'):\n",
    "        for item in each:\n",
    "            split_details = list(item.stripped_strings)\n",
    "            if 'Review' in split_details:\n",
    "                link=item.find(\"a\", href=re.compile('^https://www.etsy.com/shop/jetchcreations/reviews/'))\n",
    "                target_index = split_details.index('#')\n",
    "                newList=split_details[:target_index+2]\n",
    "                orderNo=newList[-1]\n",
    "                orderID.append(int(orderNo))\n",
    "                buyerName=newList[0]\n",
    "                buyer.append(buyerName)\n",
    "                email_address=newList[-3]\n",
    "                email.append(email_address)\n",
    "\n",
    "    reviews2_df=pd.DataFrame({'orderID':orderID,\n",
    "                         'Name':buyer,\n",
    "                         'email':email})\n",
    "\n",
    "    # Convert all objects in dataframe to strings and fill N/A with whitespace\n",
    "    reviews2_df = reviews2_df.applymap(str)\n",
    "    reviews2_df.fillna(\"\", inplace=True)\n",
    "\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF Complete- reviews2_df\")\n",
    "    print(\"DF Complete- reviews2_df\")\n",
    "\n",
    "except:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} ***ERROR: CREATING REVIEWS2_DF\")    \n",
    "    print(\"***ERROR: CREATING REVIEWS2_DF\")\n",
    "    \n",
    "# Do the following if the dataframe is not empty\n",
    "if reviews2_df.empty == False:\n",
    "\n",
    "    # Append new favorites to database\n",
    "    # Call firebase database\n",
    "    reviews2_db = \"reviews2.json\"\n",
    "    r = requests.get(config.databaseURL + reviews2_db)\n",
    "    r = r.json()\n",
    "\n",
    "    # If database is not empty create df\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "\n",
    "    else:\n",
    "        txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/data_collection_log.txt\",\"a\")\n",
    "        txt_file.write(f\"\\n{datetime.now()} ***ERROR: Access Firebase Reviews2\")\n",
    "        print(\"***ERROR: Access Firebase Reviews2\")\n",
    "        \n",
    "    # Create tuples of data that already exisits in database\n",
    "    reviewsTuples = [(item.email, item.Name, item.orderID) for index, item in df_fb.iterrows()]\n",
    "\n",
    "    # Assign variable to database where information will be pushed\n",
    "    ref = db.reference('reviews2')\n",
    "\n",
    "    # Count of items pushed to database\n",
    "    count=0\n",
    "\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    for index, item in reviews2_df.iterrows():\n",
    "        # Create tuples from local df\n",
    "        var_o=item.email,item.Name,item.orderID\n",
    "\n",
    "        if var_o not in reviewsTuples:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "\n",
    "            # Add to new favorites count\n",
    "            count += 1\n",
    "\n",
    "            # Convert tuples to string and place them in a text file\n",
    "            tup=str(var_o).replace(\"(\",\"\")\n",
    "            str_tup=tup.replace(\")\",\"\")\n",
    "            str_tup2=str_tup.replace(\"'\",\"\")\n",
    "\n",
    "            data_collection_log = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/reviews2.txt\",\"a\")\n",
    "            data_collection_log.write(f\"\\n{str_tup2}\")  \n",
    "\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to Reviews2\")\n",
    "    print(f\"Firebase- {count} records added to Reviews2\")\n",
    "    \n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- Reviews2\")\n",
    "    print(\"DF EMPTY- Reviews2\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrape - Listing Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing IDs Scraped\n"
     ]
    }
   ],
   "source": [
    "#----------------- LISTING ID SCRAPE ------------------#\n",
    "\n",
    "try:\n",
    "    # # Scrape - Listing IDs\n",
    "    # Create list for listing ids and query urls to gather stats for individual listings\n",
    "    active_listing_ids=[]\n",
    "    active_listing_query_urls=[]\n",
    "\n",
    "    # Page with all active listing ids \n",
    "    request_url=\"https://www.etsy.com/your/shops/jetchcreations/tools/listings/view:table,stats:true\"\n",
    "\n",
    "    # Navigate to page with all active listing ids\n",
    "    driver.get(request_url)\n",
    "\n",
    "    sleep(2)\n",
    "\n",
    "    html=driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    listings_page=soup.find_all('a',class_='display-block')\n",
    "\n",
    "    # Scrape listings page for listing id and create query urls\n",
    "    for listing in listings_page:\n",
    "        if listing.has_attr(\"href\"):\n",
    "            listing_ids=listing['href']\n",
    "            if '/your/shops/jetchcreations/tools/listings/' in listing_ids:\n",
    "                listing_id=listing_ids.replace('/your/shops/jetchcreations/tools/listings/','').replace('?ref=listing_row_image&from_page=/your/listings','')\n",
    "                active_listing_ids.append(listing_id)\n",
    "\n",
    "                query_url='https://www.etsy.com/your/shops/me/stats/listings/'+listing_id+'?date_range=yesterday'\n",
    "                active_listing_query_urls.append(query_url)\n",
    "\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Listing IDs scraped\")\n",
    "    print(\"Listing IDs Scraped\")\n",
    "    \n",
    "except:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} ***ERROR: LISTING ID SCRAPE\")\n",
    "    print(\"***ERROR: LISTING ID SCRAPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Listing Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------- LISTING STATS ------------------#\n",
    "\n",
    "# # Scrape - Listing Stats\n",
    "# Create lists to hold query information\n",
    "visits=[]\n",
    "itemsSold=[]\n",
    "revenue=[]\n",
    "try:\n",
    "    # Loop through listings to gather stats\n",
    "    for link in active_listing_query_urls:\n",
    "        driver.get(link)\n",
    "        sleep(2)\n",
    "\n",
    "        html=driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        visit_location=soup.find_all('div',class_='block-grid-item')\n",
    "\n",
    "        counter=0\n",
    "\n",
    "        for i in visit_location:\n",
    "\n",
    "            visit=i.find('div',class_='col-xs-7 pl-xs-0 pr-xs-0 text-right').text\n",
    "            if counter == 0:\n",
    "                visit=visit.replace(' visits','').replace(' visit','')\n",
    "                visits.append(visit)\n",
    "            if counter == 1:\n",
    "                visit=visit.replace(' items sold','').replace(' item sold','')\n",
    "                itemsSold.append(visit)\n",
    "            if counter == 2:\n",
    "                visit=visit.replace('$','')\n",
    "                revenue.append(visit)\n",
    "            counter += 1  \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Listing stats scraped\")\n",
    "    print(\"Listing Stats Scraped\")\n",
    "                    \n",
    "except:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} ***ERROR: LISTING STATS SCRAPE\")\n",
    "    print(\"***ERROR: LISTING STATS SCRAPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing_Stats DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create listing_stats_df\n",
    "listing_stats_df=pd.DataFrame({'listingID':active_listing_ids,\n",
    "'visits':visits,\n",
    "'sold':itemsSold,\n",
    "'revenue':revenue\n",
    "})\n",
    "listing_stats_df['record_date']=yesterday_full_date\n",
    "\n",
    "# Turn all objects in dataframe to strings and fill NAN with whitespace\n",
    "listing_stats_df = listing_stats_df.applymap(str)\n",
    "listing_stats_df.fillna(\"\", inplace=True)\n",
    "\n",
    "data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "data_collection_log.write(f\"\\n{datetime.now()} DF Complete- listing_stats_df\")\n",
    "print(\"DF Complete- listing_stats_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the following if the dataframe is not empty\n",
    "if listing_stats_df.empty == False:\n",
    "\n",
    "    # Call firebase database    \n",
    "    fb_db = \"listing_stats.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "    \n",
    "    # If database is not empty create df\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Firebase Listing_Stats\")\n",
    "        print(\"***ERROR- Access Firebase Listing_Stats\")\n",
    "    \n",
    "    # Create tuples of data that already exisits in database\n",
    "    df_fb_tups = [(item.listingID,item.record_date,item.revenue,item.sold,item.visits) for index, item in df_fb.iterrows()]\n",
    "\n",
    "    # Assign variable to database where information will be pushed\n",
    "    ref = db.reference('listing_stats')\n",
    "    \n",
    "    # Count of items pushed to database\n",
    "    count=0\n",
    "    \n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    for index, item in listing_stats_df.iterrows():\n",
    "        \n",
    "        # Create tuples from local df\n",
    "        var_o=item.listingID,item.record_date,item.revenue,item.sold,item.visits\n",
    "        \n",
    "        if var_o not in df_fb_tups:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "            \n",
    "            # Add to new favorites count            \n",
    "            count += 1\n",
    "            \n",
    "            # Convert tuples to string and place them in a text file\n",
    "            tup=str(var_o).replace(\"(\",\"\")\n",
    "            str_tup=tup.replace(\")\",\"\")\n",
    "            str_tup2=str_tup.replace(\"'\",\"\")\n",
    "            \n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/listing_stats.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{str_tup2}\")  \n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{now} Firebase- {count} records added to Listing_Stats\")\n",
    "    print(f\"Firebase- {count} records added to Listing_Stats\")\n",
    "    \n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- LISTING STATS\")\n",
    "    print(\"***ERROR- Firebase Listing_Stats\")\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Open Orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------- OPEN ORDERS ------------------#\n",
    "\n",
    "# # Scrape - Open Orders\n",
    "# Create lists to hold query information\n",
    "open_order_id=[]\n",
    "open_order_query_urls=[]\n",
    "ship_by_date=[]\n",
    "order_time=[]\n",
    "\n",
    "email=[]\n",
    "orderID=[]\n",
    "buyer=[]\n",
    "\n",
    "# Navigate to page\n",
    "open_order_page_url=\"https://www.etsy.com/your/orders/sold?ref=seller-platform-mcnav\"\n",
    "\n",
    "driver.get(open_order_page_url)\n",
    "sleep(2)\n",
    "\n",
    "html=driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# Gather buyer contact information\n",
    "try:\n",
    "    for each in soup.find_all('div',class_='panel-body-row'):\n",
    "        for item in each:\n",
    "            split_details = list(item.stripped_strings)\n",
    "            if 'View user profile' in split_details:\n",
    "                # Find index of generic item in list\n",
    "                target_index = split_details.index('#')\n",
    "                # Create new shorter list and then extract information needed\n",
    "                newList=split_details[:target_index+2]\n",
    "                orderNo=newList[-1]\n",
    "                orderID.append(orderNo)\n",
    "                buyerName=newList[0]\n",
    "                buyer.append(buyerName)\n",
    "                email_address=newList[-3]\n",
    "                email.append(email_address)\n",
    "\n",
    "\n",
    "    buyer_contact=pd.DataFrame({'orderID':orderID,\n",
    "                         'Name':buyer,\n",
    "                         'email':email})\n",
    "   \n",
    "    # Convert all objects in dataframe to strings and fill N/A with whitespace\n",
    "    buyer_contact = buyer_contact.applymap(str)\n",
    "    buyer_contact.fillna(\"\", inplace=True)\n",
    "\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF Complete- buyer_contact\")\n",
    "    print(\"DF Complete- buyer_contact\")\n",
    "    \n",
    "    # Locate html to scrape\n",
    "    open_orders_page=soup.find_all('div',class_='col-xs-12 col-md-8')\n",
    "\n",
    "    for orders in open_orders_page:\n",
    "        customer_name=orders.find('span',id=\"unsanitize\")\n",
    "\n",
    "\n",
    "    open_orders_page=soup.find_all('h2',class_='col-xs-5 col-md-12 text-body-smaller text-gray')\n",
    "\n",
    "\n",
    "    # Loop through html to find order IDs to create URLS\n",
    "    for orders in open_orders_page:\n",
    "        open_order_url=orders.find('a',class_='text-gray')['href']\n",
    "\n",
    "        open_order_id_value=open_order_url.replace('/your/orders/sold?ref=seller-platform-mcnav&order_id=','').replace('/your/orders/sold?order_id=','')\n",
    "        open_order_id.append(open_order_id_value)\n",
    "\n",
    "        open_order_url=\"https://www.etsy.com\"+open_order_url\n",
    "        open_order_query_urls.append(open_order_url)\n",
    "\n",
    "    # Loop through open order pages and append target info to lists\n",
    "    for url in open_order_query_urls:\n",
    "\n",
    "        driver.get(url)\n",
    "        sleep(2)\n",
    "\n",
    "        html=driver.page_source\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        tomorrow = date.today() + timedelta(days=1)\n",
    "\n",
    "        ship_by_date_values=soup.find('div',class_='flag-img flag-img-right no-wrap text-right vertical-align-bottom hide-xs hide-sm').find('div',class_='strong').text\n",
    "\n",
    "        ship_by_date_values=ship_by_date_values.replace('Ship by ','')\n",
    "\n",
    "        def validate(date_text):\n",
    "            try:\n",
    "                datetime.strptime(ship_by_date_values, '%b %d, %Y')\n",
    "                return True\n",
    "            except ValueError:\n",
    "                return False\n",
    "\n",
    "        if validate(ship_by_date_values) == True:\n",
    "            d = datetime.strptime(ship_by_date_values, '%b %d, %Y')\n",
    "        elif ship_by_date_values == 'today':\n",
    "            d = today\n",
    "        else:\n",
    "            d=tomorrow\n",
    "\n",
    "        ship_by_date_values=d.strftime('%Y-%m-%d')\n",
    "\n",
    "        ship_by_date.append(ship_by_date_values)\n",
    "\n",
    "        order_date_values=soup.find('div',class_='flag-img flag-img-right no-wrap text-right vertical-align-bottom hide-xs hide-sm').find('div',class_='text-body-smaller mt-xs-1').text\n",
    "\n",
    "        order_date_values=order_date_values.replace('Ordered ','')\n",
    "        order_date_values = order_date_values.strip(' ')\n",
    "        d = datetime.strptime(order_date_values, '%I:%M%p, %a, %b %d, %Y')\n",
    "        order_date_values=d.strftime('%m%d%y')\n",
    "        order_time_values=d.strftime('%H:%M')\n",
    "        order_time.append(order_time_values)\n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Open orders scraped\")\n",
    "    print(\"Open orders scraped\")\n",
    "    \n",
    "    orders_df_temp2=pd.DataFrame({'orderID':open_order_id,\n",
    "    'orderURL':open_order_query_urls,\n",
    "    'shipByDate':ship_by_date,\n",
    "    'orderTime':order_time})\n",
    "    orders_df_temp2['record_date']=yesterday\n",
    "\n",
    "    # Turn all objects in dataframe to strings and replace NaN with whitespace\n",
    "    orders_df_temp2 = orders_df_temp2.applymap(str)\n",
    "    orders_df_temp2.fillna(\"\", inplace=True)\n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF Complete- orders_df_temp2\")\n",
    "    print(\"DF Complete- orders_df_temp2\")\n",
    "\n",
    "    open_orders_df=pd.merge(orders_df_temp2,buyer_contact,on='orderID',how='inner')\n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF Complete- open_orders_df\")\n",
    "    print(\"DF Complete- open_orders_df\")\n",
    "\n",
    "except:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} ***ERROR: OPEN ORDERS SCRAPE\")\n",
    "    print(\"***ERROR: OPEN ORDERS SCRAPE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Search Terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Terms DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------- SEARCH TERMS ------------------#\n",
    "# # Scrape - Search Terms\n",
    "search_terms_list=[]\n",
    "search_terms_list2=[]\n",
    "search_terms_list3 = []\n",
    "search_terms_list4=[]\n",
    "search_terms_count=[]\n",
    "try:\n",
    "    request_url='https://www.etsy.com/your/shops/me/stats/traffic?ref=seller-platform-mcnav&date_range=yesterday'\n",
    "\n",
    "    driver.get(request_url)\n",
    "    sleep(3)\n",
    "\n",
    "    html=driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "\n",
    "    soup=BeautifulSoup(html,'lxml')\n",
    "\n",
    "    table=soup.find_all('table')[0]\n",
    "\n",
    "    tr_data=table.find_all('tr')\n",
    "\n",
    "    for tr in tr_data[1:]:\n",
    "        td = tr.find_all('td')\n",
    "        row = [tr.text for tr in td]\n",
    "        search_terms_list.append(row)\n",
    "\n",
    "\n",
    "    #turn list of lists into a single list\n",
    "    for sublist in search_terms_list:\n",
    "        for item in sublist:\n",
    "            search_terms_list2.append(item)\n",
    "\n",
    "\n",
    "\n",
    "    # split: \\d is a digit (a character in the range 0-9), and + means 1 or more times. So, \\d+ is 1 or more digits.\n",
    "    for l in search_terms_list2:\n",
    "        simple=re.split('(\\d+)',l)\n",
    "        search_terms_list3.append(simple[0])\n",
    "        search_terms_count.append(simple[-2])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    for string in search_terms_list3:\n",
    "        string = re.sub('[^a-zA-Z.\\d\\s]', '', string)\n",
    "        search_terms_list4.append(string)\n",
    "\n",
    "    #remove leading and trailing spaces\n",
    "    search_terms_list4 = [x.strip(' ') for x in search_terms_list4]\n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Search terms scraped\")\n",
    "    print(\"Search terms scraped\")\n",
    "    \n",
    "    search_terms_df=pd.DataFrame({\"searchTerms\":search_terms_list4,\n",
    "    \"count\":search_terms_count})\n",
    "    search_terms_df['record_date']=yesterday_full_date\n",
    "    # Turn all objects in dataframe to strings and fill NAN with whitespace\n",
    "    search_terms_df = search_terms_df.applymap(str)\n",
    "    search_terms_df.fillna(\"\", inplace=True)\n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF Complete- search_terms_df\")\n",
    "    print(\"DF Complete- search_terms_df\")\n",
    "    \n",
    "    # Convert df to list\n",
    "    items=search_terms_df.values.tolist()\n",
    "    \n",
    "    # Loop through each item in list\n",
    "    for item in items:\n",
    "        # Remove brackets form list and write to text file\n",
    "        new_val= \", \".join( repr(e) for e in item ) \n",
    "        new_val2=new_val.replace(\"'\",\"\")\n",
    "        \n",
    "        txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/search_terms.txt\",\"a\")\n",
    "        txt_file.write(f\"\\n{new_val2}\") \n",
    "    \n",
    "except:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} ***ERROR: SEARCH TERMS SCRAPE\")\n",
    "    print(\"***ERROR: SEARCH TERMS SCRAPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape - CSV Downloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------- CSV DOWNLOADS ------------------#\n",
    "try:\n",
    "    # # Scrape - Download CSV Files\n",
    "    # Navigate to download page\n",
    "    driver.get(\"https://www.etsy.com/your/shops/jetchcreations/download\" )\n",
    "    # Select options from dropdown lists & submit to begin download\n",
    "    # After download the page will refresh to prevent system notifications\n",
    "    select = Select(driver.find_element_by_id('filter-csv-type'))\n",
    "    select.select_by_value('transaction-level')\n",
    "\n",
    "    select = Select(driver.find_element_by_id('filter-year'))\n",
    "    select.select_by_value('2019')\n",
    "\n",
    "    button=driver.find_element_by_id('order-csv-form')\n",
    "    button.submit()\n",
    "\n",
    "    sleep(5)\n",
    "    driver.refresh()\n",
    "    sleep(3)\n",
    "\n",
    "    select = Select(driver.find_element_by_id('filter-csv-type'))\n",
    "    select.select_by_value('payments-level')\n",
    "\n",
    "    select = Select(driver.find_element_by_id('filter-year'))\n",
    "    select.select_by_value(yesterday_year)\n",
    "\n",
    "    button=driver.find_element_by_id('order-csv-form')\n",
    "    button.submit()\n",
    "\n",
    "    sleep(5)\n",
    "    driver.refresh()\n",
    "    sleep(3)\n",
    "\n",
    "    select = Select(driver.find_element_by_id('filter-csv-type'))\n",
    "    select.select_by_value('order-level')\n",
    "\n",
    "    select = Select(driver.find_element_by_id('filter-year'))\n",
    "    select.select_by_value(yesterday_year)\n",
    "\n",
    "    button=driver.find_element_by_id('order-csv-form')\n",
    "    button.submit()\n",
    "\n",
    "    sleep(5)\n",
    "    driver.refresh()\n",
    "    sleep(3)\n",
    "\n",
    "    select = Select(driver.find_element_by_id('filter-csv-type'))\n",
    "    select.select_by_value('disbursements-level')\n",
    "\n",
    "    select = Select(driver.find_element_by_id('filter-year'))\n",
    "    select.select_by_value(yesterday_year)\n",
    "\n",
    "    button=driver.find_element_by_id('order-csv-form')\n",
    "    button.submit()\n",
    "\n",
    "    sleep(10)\n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} CSV download complete\") \n",
    "    print(\"CSV download complete\")\n",
    "except:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- CSV DOWNLOAD\")\n",
    "    print(\"***ERROR- CSV DOWNLOAD\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Read in CSVs to dataframes\n",
    "    sold_orders_file_path=(f\"/Users/jessicaetchechury/Downloads/EtsySoldOrders{yesterday_year}.csv\")\n",
    "    sold_orders_df=pd.read_csv(sold_orders_file_path)\n",
    "    # Convert data types to string\n",
    "    sold_orders_df = sold_orders_df.applymap(str)\n",
    "\n",
    "    sold_order_items_file_path=(f\"/Users/jessicaetchechury/Downloads/EtsySoldOrderItems{yesterday_year}.csv\")\n",
    "    sold_order_items_df=pd.read_csv(sold_order_items_file_path)\n",
    "    # Convert data types to string\n",
    "    sold_order_items_df = sold_order_items_df.applymap(str)\n",
    "\n",
    "    direct_checkout_payments_file_path=(f\"/Users/jessicaetchechury/Downloads/EtsyDirectCheckoutPayments{yesterday_year}.csv\")\n",
    "    direct_checkout_payments_df=pd.read_csv(direct_checkout_payments_file_path)\n",
    "    # Convert data types to string\n",
    "    direct_checkout_payments_df = direct_checkout_payments_df.applymap(str)\n",
    "\n",
    "    deposits_file_path=(f\"/Users/jessicaetchechury/Downloads/EtsyDeposits{yesterday_year}.csv\")\n",
    "    deposits_df=pd.read_csv(deposits_file_path)\n",
    "    # Convert data types to string\n",
    "    deposits_df = deposits_df.applymap(str)\n",
    "\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} CSV to pandas df complete\") \n",
    "    print(\"CSV to pandas df complete\")\n",
    "    \n",
    "    # Move CSVs to storage\n",
    "    os.rename(f\"/Users/jessicaetchechury/Downloads/EtsySoldOrders{yesterday_year}.csv\",f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/CSV_Downloads/EtsySoldOrders{yesterday_full_date}.csv\")\n",
    "    os.rename(f\"/Users/jessicaetchechury/Downloads/EtsyDirectCheckoutPayments{yesterday_year}.csv\",f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/CSV_Downloads/EtsyDirectCheckoutPayments{yesterday_full_date}.csv\")\n",
    "    os.rename(f\"/Users/jessicaetchechury/Downloads/EtsySoldOrderItems{yesterday_year}.csv\",f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/CSV_Downloads/EtsySoldOrderItems{yesterday_full_date}.csv\")\n",
    "    os.rename(f\"/Users/jessicaetchechury/Downloads/EtsyDeposits{yesterday_year}.csv\",f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/CSV_Downloads/EtsyDeposits{yesterday_full_date}.csv\")\n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} CSV transfer complete\") \n",
    "    print(\"CSV transfer complete\")\n",
    "    \n",
    "except:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- CSV TO PANDAS DF\") \n",
    "    print(\"***ERROR- CSV TO PANDAS DF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Revenue "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------- REVENUE ------------------#\n",
    "try:\n",
    "    # Scrape Revenue\n",
    "    url=\"https://www.etsy.com/your/account/payments?ref=seller-platform-mcnav\"\n",
    "\n",
    "    driver.get(url)\n",
    "    sleep(2)\n",
    "\n",
    "    html=driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    sales_credits=driver.find_element_by_xpath('//*[@id=\"root\"]/div/div[3]/div/div[4]/div/div[2]/div[1]/div/div[1]/div[2]/h4/span/span[2]').text\n",
    "\n",
    "    fees_taxes=driver.find_element_by_xpath('//*[@id=\"root\"]/div/div[3]/div/div[4]/div/div[2]/div[2]/div/div[1]/div[2]/h4/span/span/span[2]').text\n",
    "\n",
    "    orderRevenue=[]\n",
    "    orderNet = float(sales_credits) - float(fees_taxes)\n",
    "\n",
    "    orderRevenue.append(orderNet)\n",
    "    \n",
    "    orderNet_df=pd.DataFrame({'orderNet':orderRevenue})\n",
    "    orderNet_df['date']=today.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # Convert all objects in dataframe to strings and fill NaN with whitespace\n",
    "    orderNet_df = orderNet_df.applymap(str)\n",
    "    orderNet_df.fillna(\"\", inplace=True)\n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF Complete- orderNet_df\")\n",
    "    print(\"DF Complete- orderNet_df\")\n",
    "    \n",
    "    # Do the following if the dataframe is not empty\n",
    "    if orderNet_df.empty == False:\n",
    "        \n",
    "        # Append new favorites to database\n",
    "        \n",
    "        # Call firebase database\n",
    "        fb_db = \"order_net.json\"\n",
    "        r = requests.get(config.databaseURL + fb_db)\n",
    "        r = r.json()\n",
    "    \n",
    "        # If database is not empty create df\n",
    "        if r:\n",
    "            data = [r[i] for i in r]\n",
    "            df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "            df_fb = df_fb.applymap(str)\n",
    "\n",
    "        else:\n",
    "            data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "            data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase Order_Net\")\n",
    "            print(\"***ERROR- Acess Firebase Order_Net\")\n",
    "            \n",
    "        # Create tuples of data that already exisits in database\n",
    "        df_fb_tups = [(item.date, item.orderNet) for index, item in df_fb.iterrows()]\n",
    "\n",
    "        # Assign variable to database where information will be pushed\n",
    "        ref = db.reference('order_net')\n",
    "        \n",
    "        # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "        for index, item in orderNet_df.iterrows():\n",
    "            # Create tuples from local df\n",
    "            var_o=item.date, item.orderNet\n",
    "            if var_o not in df_fb_tups:\n",
    "                # Push item to db\n",
    "                ref.push(item.to_dict()) \n",
    "                \n",
    "                # Convert tuples to string and place them in a text file\n",
    "                tup=str(var_o).replace(\"(\",\"\")\n",
    "                str_tup=tup.replace(\")\",\"\")\n",
    "                str_tup2=str_tup.replace(\"'\",\"\")\n",
    "                \n",
    "                txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/order_net.txt\",\"a\")\n",
    "                txt_file.write(f\"\\n{str_tup2}\")  \n",
    "            \n",
    "                \n",
    "            else:\n",
    "                data_collection_log = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/order_net.txt\",\"a\")\n",
    "                data_collection_log.write(f\"\\n{datetime.now()} Order_net already in database\")  \n",
    "                print(\"Order_net already in database\")\n",
    "except:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- ORDER NET\")\n",
    "    print(\"***ERROR- ORDER NET\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API CALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------- API CALL ------------------#\n",
    "\n",
    "# # API Call - Listing Images\n",
    "image_listing_id=[]\n",
    "listing_image_id=[]\n",
    "listing_image_url_fullxfull=[]\n",
    "listing_image_rank=[]\n",
    "\n",
    "try:\n",
    "    for listing in active_listing_ids:\n",
    "        query_url=\"https://openapi.etsy.com/v2/listings/\"+listing+\"/images?api_key=\"+config.api_key\n",
    "        listing_images_query=requests.get(query_url).json()\n",
    "\n",
    "        try:\n",
    "            listing_images_results=listing_images_query[\"results\"]\n",
    "\n",
    "            for item in listing_images_results:\n",
    "                for key,value in item.items():\n",
    "                    if key=='listing_image_id':\n",
    "                        listing_image_id.append(value)\n",
    "                    if key=='url_fullxfull':\n",
    "                        listing_image_url_fullxfull.append(value)\n",
    "                    if key=='listing_id':\n",
    "                        image_listing_id.append(value)\n",
    "                    if key=='rank':\n",
    "                        listing_image_rank.append(value)\n",
    "\n",
    "        except(KeyError, IndexError):\n",
    "            print(\"error\")\n",
    "\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Listing images scraped\")\n",
    "    print(\"Listing information scraped\") \n",
    "\n",
    "except:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Listing images Scrape\")\n",
    "    print(\"***ERROR- Listing Images Scrape\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # API Call - Listing Inforamtion\n",
    "listing_id=[]\n",
    "state=[]\n",
    "category_id=[]\n",
    "listing_title=[]\n",
    "title=[]\n",
    "description=[]\n",
    "date_created=[]\n",
    "date_expires=[]\n",
    "last_modified=[]\n",
    "price=[]\n",
    "quantity=[]\n",
    "tags=[]\n",
    "category_path=[]\n",
    "shop_section_id=[]\n",
    "listing_url=[]\n",
    "shipping_template_id=[]\n",
    "processing_min=[]\n",
    "processing_max=[]\n",
    "item_weight=[]\n",
    "item_weight_unit=[]\n",
    "item_length=[]\n",
    "item_width=[]\n",
    "item_height=[]\n",
    "item_dimensions_unit=[]\n",
    "occasion=[]\n",
    "is_customizable=[]\n",
    "is_digital=[]\n",
    "has_variations=[]\n",
    "views=[]\n",
    "num_favorites=[]\n",
    "\n",
    "try:\n",
    "    for listing in active_listing_ids:\n",
    "\n",
    "        query_url=\"https://openapi.etsy.com/v2/listings/\"+listing+\"?api_key=\"+config.api_key\n",
    "\n",
    "        listing_info_query=requests.get(query_url).json()\n",
    "\n",
    "        try:\n",
    "            listing_info_results=listing_info_query[\"results\"]\n",
    "\n",
    "            for item in listing_info_results:\n",
    "\n",
    "                for key,value in item.items():\n",
    "                    if key=='views':\n",
    "                        views.append(value)\n",
    "                    if key=='num_favorers':\n",
    "                        num_favorites.append(value)\n",
    "                    if key=='listing_id':\n",
    "                        listing_id.append(value)\n",
    "                    if key=='state':\n",
    "                        state.append(value)\n",
    "                    if key=='category_id':\n",
    "                        category_id.append(value)\n",
    "                    if key=='title':\n",
    "                        listing_title.append(value)\n",
    "                    if key=='description':\n",
    "                        description.append(value)\n",
    "                    if key=='creation_tsz':\n",
    "                        date_created.append(value)\n",
    "                    if key=='ending_tsz':\n",
    "                        date_expires.append(value)\n",
    "                    if key=='last_modified_tsz':\n",
    "                        last_modified.append(value)\n",
    "                    if key=='price':\n",
    "                        price.append(value)\n",
    "                    if key=='quantity':\n",
    "                        quantity.append(value)\n",
    "                    if key=='tags':\n",
    "                        tags.append(value)\n",
    "                    if key=='category_path':\n",
    "                        category_path.append(value)\n",
    "                    if key=='shop_section_id':\n",
    "                        shop_section_id.append(value)\n",
    "                    if key=='url':\n",
    "                        listing_url.append(value)\n",
    "                    if key=='shipping_template_id':\n",
    "                        shipping_template_id.append(value)\n",
    "                    if key=='processing_min':\n",
    "                        processing_min.append(value)\n",
    "                    if key=='processing_max':\n",
    "                        processing_max.append(value)\n",
    "                    if key=='item_weight':\n",
    "                        item_weight.append(value)\n",
    "                    if key=='item_weight_unit':\n",
    "                        item_weight_unit.append(value)\n",
    "                    if key=='item_length':\n",
    "                        item_length.append(value)\n",
    "                    if key=='item_width':\n",
    "                        item_width.append(value)\n",
    "                    if key=='item_height':\n",
    "                        item_height.append(value)\n",
    "                    if key=='item_dimensions_unit':\n",
    "                        item_dimensions_unit.append(value)\n",
    "                    if key=='occasion':\n",
    "                        occasion.append(value)\n",
    "                    if key=='is_customizable':\n",
    "                        is_customizable.append(value)\n",
    "                    if key=='is_digital':\n",
    "                        is_digital.append(value)\n",
    "                    if key=='has_variations':\n",
    "                        has_variations.append(value)\n",
    "\n",
    "        except(KeyError, IndexError):\n",
    "            print(\"error\")\n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Listing information scraped\")\n",
    "    print(\"Listing information scraped\") \n",
    "    \n",
    "except:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Listing Information Scrape\")\n",
    "    print(\"***ERROR- Listing Information Scrape\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Listing_IDs DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create listing_id_df\n",
    "listing_id_df=pd.DataFrame({'listingID':active_listing_ids,\n",
    "'title':listing_title\n",
    "})\n",
    "listing_id_df['title'] = listing_id_df['title'].str.split(': ').str[1]\n",
    "\n",
    "listing_id_df = listing_id_df.applymap(str)\n",
    "listing_id_df.fillna(\"\", inplace=True)\n",
    "\n",
    "data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "data_collection_log.write(f\"\\n{datetime.now()} DF Complete- listing_id_df\")\n",
    "print(\"DF Complete- listing_id_df\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the following if the dataframe is not empty\n",
    "if listing_id_df.empty == False:\n",
    "    \n",
    "    #Only push new records\n",
    "    listingIds_db = \"listing_ids.json\"\n",
    "    r = requests.get(config.databaseURL + listingIds_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase listing_id_df\")\n",
    "        print(\"***ERROR- Acess Firebase listing_id_df\")\n",
    "        \n",
    "    listingIdsTuples = [(item.listingID, item.title) for index, item in df_fb.iterrows()]\n",
    "\n",
    "    ref = db.reference('listing_ids')\n",
    "    \n",
    "    # New record count\n",
    "    count=0\n",
    "    new_ListingID=[]\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    for index, item in listing_id_df.iterrows():\n",
    "        \n",
    "        # Create tuples from local df        \n",
    "        var_o=item.listingID,item.title\n",
    "        \n",
    "        if var_o not in listingIdsTuples:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "            # Convert tuples to string and place them in a text file\n",
    "            tup=str(var_o).replace(\"(\",\"\")\n",
    "            str_tup=tup.replace(\")\",\"\")\n",
    "            str_tup2=str_tup.replace(\"'\",\"\")\n",
    "            \n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/listing_ids.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{str_tup2}\")  \n",
    "            \n",
    "        else:\n",
    "            pass            \n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to Listing_IDs\")\n",
    "    print(f\"Firebase- {count} records added to Listing_IDs\")\n",
    "\n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- Listing_IDs\")\n",
    "    print(\"DF EMPTY- Listing_IDs\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe of new listingIDs to be added to listing creation database\n",
    "try:\n",
    "    listing_id_creation_df=pd.DataFrame({'ListingID':new_ListingID\n",
    "    })\n",
    "    listing_id_creation_df['OriginallyCreated']=yesterday_full_date\n",
    "\n",
    "    # Convert all objects in dataframe to strings and fill N/A with whitespace\n",
    "    listing_id_creation_df = listing_id_creation_df.applymap(str)\n",
    "    listing_id_creation_df.fillna(\"\", inplace=True)\n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF Complete- listing_id_creation_df\")\n",
    "    print(\"DF Complete- listing_id_creation_df\")\n",
    "\n",
    "except:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} ***ERROR: DF- listing_id_creation_df\")\n",
    "    print(\"***ERROR: DF- listing_id_creation_df\")\n",
    "    \n",
    "    \n",
    "if listing_id_creation_df.empty == False:\n",
    "    fb_db = \"listing_creation_dates.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase listing_creation_dates\")\n",
    "        print(\"***ERROR- Acess Firebase listing_creation_dates\")\n",
    "\n",
    "    df_tups = [(item.ListingID,item.OriginallyCreated) for index, item in df_fb.iterrows()]\n",
    "\n",
    "    ref = db.reference('listing_creation_dates')\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "\n",
    "    # New record count\n",
    "    count=0\n",
    "\n",
    "    for index, item in listing_id_creation_df.iterrows():\n",
    "\n",
    "        # Create tuples from local df        \n",
    "        var_o=item.ListingID,item.OriginallyCreated\n",
    "\n",
    "        if var_o not in df_tups:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "\n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "\n",
    "            items=item.values.tolist()\n",
    "\n",
    "            new_val= \", \".join( repr(e) for e in items ) \n",
    "\n",
    "            new_val2=new_val.replace(\"'\",\"\")\n",
    "\n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/listing_creation.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{new_val2}\") \n",
    "            print(new_val2)\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to listing_creation_dates\")\n",
    "    print(f\"Firebase- {count} records added to listing_creation_dates\")\n",
    "\n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- listing_id_creation_df\")\n",
    "    print(\"DF EMPTY- listing_id_creation_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing_Info DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create listing_info_df\n",
    "listing_info_df=pd.DataFrame({'listingID':active_listing_ids,\n",
    "'listingTitle':listing_title,\n",
    "'state':state,\n",
    "'digital':is_digital,\n",
    "'customizable':is_customizable,\n",
    "'variations':has_variations,\n",
    "'dateCreated':date_created,\n",
    "'dateExpires':date_expires,\n",
    "'lastModified':last_modified,\n",
    "'url':listing_url\n",
    "})\n",
    "\n",
    "\n",
    "listing_info_df['dateCreated']=pd.to_datetime(listing_info_df[\"dateCreated\"], unit = 's')\n",
    "listing_info_df['dateCreated']= listing_info_df['dateCreated'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "listing_info_df['dateExpires']=pd.to_datetime(listing_info_df[\"dateExpires\"], unit = 's')\n",
    "listing_info_df['dateExpires']= listing_info_df['dateExpires'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "listing_info_df['lastModified']=pd.to_datetime(listing_info_df[\"lastModified\"], unit = 's')\n",
    "listing_info_df['lastModified']= listing_info_df['lastModified'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "listing_info_df['record_date']=yesterday_full_date\n",
    "\n",
    "listing_info_df = listing_info_df.applymap(str)\n",
    "listing_info_df.fillna(\"\", inplace=True)\n",
    "\n",
    "data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "data_collection_log.write(f\"\\n{datetime.now()} DF Complete- listing_info_df\")\n",
    "print(\"DF Complete- listing_info_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that records for the day have not already been added\n",
    "# Do the following if the dataframe is not empty\n",
    "if listing_info_df.empty == False:\n",
    "    fb_db = \"listing_info.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase listing_info_df\")\n",
    "        print(\"***ERROR- Acess Firebase listing_info_df\")\n",
    "        \n",
    "    df_tups = [(item.listingID, item.record_date) for index, item in df_fb.iterrows()]\n",
    "    \n",
    "    ref = db.reference('listing_info')\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    \n",
    "    # New record count\n",
    "    count=0\n",
    "    \n",
    "    for index, item in listing_info_df.iterrows():\n",
    "        \n",
    "        # Create tuples from local df        \n",
    "        var_o=item.listingID,item.record_date\n",
    "        \n",
    "        if var_o not in df_tups:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "            \n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "            \n",
    "            items=item.values.tolist()\n",
    "            \n",
    "            new_val= \", \".join( repr(e) for e in items ) \n",
    "            \n",
    "            new_val2=new_val.replace(\"'\",\"\")\n",
    "            \n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/listing_info.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{new_val2}\") \n",
    "            \n",
    "        else:\n",
    "            pass            \n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to Listing_IDs\")\n",
    "    print(f\"Firebase- {count} records added to Listing_IDs\")\n",
    "\n",
    "\n",
    "        \n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- Listing_Info\")\n",
    "    print(\"DF EMPTY- Listing_Info\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List_Shipping DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_shipping_df=pd.DataFrame({'listingID':active_listing_ids,\n",
    "'shippingTemplateID':shipping_template_id,\n",
    "'itemWeight':item_weight,\n",
    "'itemWeightUnit':item_weight_unit,\n",
    "'itemLength':item_length,\n",
    "'itemWidth':item_width,\n",
    "'itemHeight':item_height,\n",
    "'itemDimensionalUnit':item_dimensions_unit,\n",
    "})\n",
    "\n",
    "listing_shipping_df['record_date']=yesterday_full_date\n",
    "\n",
    "listing_shipping_df = listing_shipping_df.applymap(str)\n",
    "listing_shipping_df.fillna(\"\", inplace=True)\n",
    "\n",
    "data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "data_collection_log.write(f\"\\n{datetime.now()} DF Complete- listing_shipping_df\")\n",
    "print(\"DF Complete- listing_shipping_df\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that records for the day have not already been added\n",
    "# Do the following if the dataframe is not empty\n",
    "if listing_shipping_df.empty == False:\n",
    "    fb_db = \"listing_shipping.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase listing_shipping\")\n",
    "        print(\"***ERROR- Acess Firebase listing_shipping\")\n",
    "        \n",
    "    df_tups = [(item.listingID, item.record_date) for index, item in df_fb.iterrows()]\n",
    "    \n",
    "    ref = db.reference('listing_shipping')\n",
    "    \n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database  \n",
    "    # New record count\n",
    "    count=0\n",
    "    \n",
    "    for index, item in listing_shipping_df.iterrows():\n",
    "        \n",
    "        # Create tuples from local df        \n",
    "        var_o=item.listingID,item.record_date\n",
    "        \n",
    "        if var_o not in df_tups:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "            \n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "            \n",
    "            items=item.values.tolist()\n",
    "            \n",
    "            new_val= \", \".join( repr(e) for e in items ) \n",
    "            \n",
    "            new_val2=new_val.replace(\"'\",\"\")\n",
    "            \n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/listing_shipping.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{new_val2}\") \n",
    "            \n",
    "        else:\n",
    "            pass            \n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to listing_shipping\")\n",
    "    print(f\"Firebase- {count} records added to listing_shipping\")\n",
    "\n",
    "\n",
    "        \n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- listing_shipping\")\n",
    "    print(\"DF EMPTY- listing_shipping\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing_Images df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_images_df=pd.DataFrame({'listingID':image_listing_id,\n",
    "'listingImageID':listing_image_id,\n",
    "'listingImageURL':listing_image_url_fullxfull,\n",
    "'listingImageRank':listing_image_rank\n",
    "})\n",
    "\n",
    "listing_images_df['record_date']=yesterday_full_date\n",
    "\n",
    "listing_images_df = listing_images_df.applymap(str)\n",
    "listing_images_df.fillna(\"\", inplace=True)\n",
    "\n",
    "data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "data_collection_log.write(f\"\\n{datetime.now()} DF Complete- listing_images_df\")\n",
    "print(\"DF Complete- listing_images_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that records for the day have not already been added\n",
    "# Do the following if the dataframe is not empty\n",
    "if listing_images_df.empty == False:\n",
    "    fb_db = \"listing_images.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase listing_images\")\n",
    "        print(\"***ERROR- Acess Firebase listing_images\")\n",
    "        \n",
    "    df_tups = [(item.listingID, item.record_date) for index, item in df_fb.iterrows()]\n",
    "    \n",
    "    ref = db.reference('listing_images')\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    \n",
    "    # New record count\n",
    "    count=0\n",
    "    \n",
    "    for index, item in listing_images_df.iterrows():\n",
    "        \n",
    "        # Create tuples from local df        \n",
    "        var_o=item.listingID,item.record_date\n",
    "        \n",
    "        if var_o not in df_tups:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "            \n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "            \n",
    "            items=item.values.tolist()\n",
    "            \n",
    "            new_val= \", \".join( repr(e) for e in items ) \n",
    "            \n",
    "            new_val2=new_val.replace(\"'\",\"\")\n",
    "            \n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/listing_images.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{new_val2}\") \n",
    "            \n",
    "        else:\n",
    "            pass            \n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to Listing_Images\")\n",
    "    print(f\"Firebase- {count} records added to Listing_Images\")\n",
    "\n",
    "\n",
    "        \n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- Listing_Images\")\n",
    "    print(\"DF EMPTY- Listing_Images\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing_Categories df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_categorical_df=pd.DataFrame({'listingID':active_listing_ids,\n",
    "'categoryID':category_id,\n",
    "'shopSectionID':shop_section_id,\n",
    "'occasion':occasion\n",
    "})\n",
    "listing_categorical_df['record_date']=yesterday_full_date\n",
    "\n",
    "listing_categorical_df = listing_categorical_df.applymap(str)\n",
    "listing_categorical_df.fillna(\"\", inplace=True)\n",
    "\n",
    "data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "data_collection_log.write(f\"\\n{datetime.now()} DF Complete- listing_categorical_df\")\n",
    "print(\"DF Complete- listing_categorical_df\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that records for the day have not already been added\n",
    "# Do the following if the dataframe is not empty\n",
    "if listing_categorical_df.empty == False:\n",
    "    fb_db = \"listing_categories.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase listing_categories\")\n",
    "        print(\"***ERROR- Acess Firebase listing_categories\")\n",
    "        \n",
    "    df_tups = [(item.listingID, item.record_date) for index, item in df_fb.iterrows()]\n",
    "    \n",
    "    ref = db.reference('listing_categories')\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    \n",
    "    # New record count\n",
    "    count=0\n",
    "    \n",
    "    for index, item in listing_categorical_df.iterrows():\n",
    "        \n",
    "        # Create tuples from local df        \n",
    "        var_o=item.listingID,item.record_date\n",
    "        \n",
    "        if var_o not in df_tups:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "            \n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "            \n",
    "            items=item.values.tolist()\n",
    "            \n",
    "            new_val= \", \".join( repr(e) for e in items ) \n",
    "            \n",
    "            new_val2=new_val.replace(\"'\",\"\")\n",
    "            \n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/listing_categories.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{new_val2}\") \n",
    "            \n",
    "        else:\n",
    "            pass            \n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to listing_categories\")\n",
    "    print(f\"Firebase- {count} records added to listing_categories\")\n",
    "\n",
    "\n",
    "        \n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- listing_categorical_df\")\n",
    "    print(\"DF EMPTY- listing_categorical_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing_tags DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create listing tags dataframe\n",
    "listing_tags_df=pd.DataFrame({'listingID':active_listing_ids,\n",
    "'tags':tags\n",
    "})\n",
    "# Split list of tags into columns\n",
    "listing_tags_df=listing_tags_df.assign(**pd.DataFrame(listing_tags_df.tags.values.tolist()).add_prefix('tag_'))\n",
    "# Melt dataframe to reduce amount of columns\n",
    "listing_tags_df=pd.melt(listing_tags_df, id_vars=['listingID'], value_vars=['tag_0',\n",
    "'tag_1',\n",
    "'tag_2',\n",
    "'tag_3',\n",
    "'tag_4',\n",
    "'tag_5',\n",
    "'tag_6',\n",
    "'tag_7',\n",
    "'tag_8',\n",
    "'tag_9',\n",
    "'tag_10',\n",
    "'tag_11',\n",
    "'tag_12'])\n",
    "# Drop any rows that do not have a tag\n",
    "listing_tags_df = listing_tags_df.dropna(axis=0, subset=['value'])\n",
    "# Rename value column to tag\n",
    "listing_tags_df=listing_tags_df.rename(columns={\"value\":\"tag\"})\n",
    "# Drop tags column\n",
    "listing_tags_df=listing_tags_df[['listingID','tag']]\n",
    "\n",
    "listing_tags_df['record_date']=yesterday_full_date\n",
    "\n",
    "listing_tags_df = listing_tags_df.applymap(str)\n",
    "listing_tags_df.fillna(\"\", inplace=True)\n",
    "\n",
    "data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "data_collection_log.write(f\"\\n{datetime.now()} DF Complete- listing_tags_df\")\n",
    "print(\"DF Complete- listing_tags_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that records for the day have not already been added\n",
    "# Do the following if the dataframe is not empty\n",
    "if listing_tags_df.empty == False:\n",
    "    fb_db = \"listing_tags.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase listing_tags\")\n",
    "        print(\"***ERROR- Acess Firebase listing_tags\")\n",
    "        \n",
    "    df_tups = [(item.listingID, item.record_date) for index, item in df_fb.iterrows()]\n",
    "    \n",
    "    ref = db.reference('listing_tags')\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    \n",
    "    # New record count\n",
    "    count=0\n",
    "    \n",
    "    for index, item in listing_tags_df.iterrows():\n",
    "        \n",
    "        # Create tuples from local df        \n",
    "        var_o=item.listingID,item.record_date\n",
    "        \n",
    "        if var_o not in df_tups:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "            \n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "            \n",
    "            items=item.values.tolist()\n",
    "            \n",
    "            new_val= \", \".join( repr(e) for e in items ) \n",
    "            \n",
    "            new_val2=new_val.replace(\"'\",\"\")\n",
    "            \n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/listing_tags.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{new_val2}\") \n",
    "            \n",
    "        else:\n",
    "            pass            \n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to listing_tags\")\n",
    "    print(f\"Firebase- {count} records added to listing_tags\")\n",
    "\n",
    "\n",
    "        \n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- listing_tags_df\")\n",
    "    print(\"DF EMPTY- listing_tags_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production_et DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_time_df=pd.DataFrame({'listingID':active_listing_ids,\n",
    "'processingTimeMin':processing_min,\n",
    "'processingTimeMax':processing_max\n",
    "})\n",
    "\n",
    "production_time_df['record_date']=yesterday_full_date\n",
    "\n",
    "production_time_df = production_time_df.applymap(str)\n",
    "production_time_df.fillna(\"\", inplace=True)\n",
    "\n",
    "data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "data_collection_log.write(f\"\\n{datetime.now()} DF Complete- production_time_df\")\n",
    "print(\"DF Complete- production_time_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that records for the day have not already been added\n",
    "# Do the following if the dataframe is not empty\n",
    "if production_time_df.empty == False:\n",
    "    fb_db = \"production_et.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase production_et\")\n",
    "        print(\"***ERROR- Acess Firebase production_et\")\n",
    "        \n",
    "    df_tups = [(item.listingID, item.record_date) for index, item in df_fb.iterrows()]\n",
    "    \n",
    "    ref = db.reference('production_et')\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    \n",
    "    # New record count\n",
    "    count=0\n",
    "    \n",
    "    for index, item in production_time_df.iterrows():\n",
    "        \n",
    "        # Create tuples from local df        \n",
    "        var_o=item.listingID,item.record_date\n",
    "        \n",
    "        if var_o not in df_tups:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "            \n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "            \n",
    "            items=item.values.tolist()\n",
    "            \n",
    "            new_val= \", \".join( repr(e) for e in items ) \n",
    "            \n",
    "            new_val2=new_val.replace(\"'\",\"\")\n",
    "            \n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/production_et.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{new_val2}\") \n",
    "            \n",
    "        else:\n",
    "            pass            \n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to production_et\")\n",
    "    print(f\"Firebase- {count} records added to production_et\")\n",
    "\n",
    "\n",
    "        \n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- production_time_df\")\n",
    "    print(\"DF EMPTY- production_time_df\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns not needed for database table\n",
    "order_sold_items_df=sold_order_items_df[['Order ID','Transaction ID','Listing ID','Quantity','Variations']]\n",
    "order_sold_items_df=order_sold_items_df.rename(columns={'Order ID':'orderID',\n",
    "'Transaction ID':'transactionID',\n",
    "'Listing ID':'listingID',\n",
    "'Quantity':'quantity',\n",
    "'Variations':'variations'})\n",
    "\n",
    "order_sold_items_df['record_date']=yesterday_full_date\n",
    "\n",
    "order_sold_items_df = order_sold_items_df.applymap(str)\n",
    "order_sold_items_df.fillna(\"\", inplace=True)\n",
    "\n",
    "data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "data_collection_log.write(f\"\\n{datetime.now()} DF Complete- order_sold_items_df\")\n",
    "print(\"DF Complete- order_sold_items_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that records for the day have not already been added\n",
    "# Do the following if the dataframe is not empty\n",
    "if order_sold_items_df.empty == False:\n",
    "    fb_db = \"order_items.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "\n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase order_items\")\n",
    "        print(\"***ERROR- Acess Firebase order_items\")\n",
    "        \n",
    "    df_tups = [(item.listingID, item.orderID) for index, item in df_fb.iterrows()]\n",
    "    \n",
    "    ref = db.reference('order_items')\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    \n",
    "    # New record count\n",
    "    count=0\n",
    "    \n",
    "    for index, item in order_sold_items_df.iterrows():\n",
    "        \n",
    "        # Create tuples from local df        \n",
    "        var_o=item.listingID, item.orderID\n",
    "        if var_o not in df_tups:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "            \n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "            \n",
    "            items=item.values.tolist()\n",
    "            \n",
    "            new_val= \", \".join( repr(e) for e in items ) \n",
    "            \n",
    "            new_val2=new_val.replace(\"'\",\"\")\n",
    "            \n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/order_items.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{new_val2}\") \n",
    "            \n",
    "        else:\n",
    "            pass            \n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to order_items\")\n",
    "    print(f\"Firebase- {count} records added to order_items\")\n",
    "\n",
    "\n",
    "        \n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- order_sold_items_df\")\n",
    "    print(\"DF EMPTY- order_sold_items_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buyers DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "# Rename columns that will be used\n",
    "    sold_orders_df2=sold_orders_df.rename(columns={'Sale Date':'orderDate',\n",
    "    'Order ID':'orderID',\n",
    "    'Buyer User ID':'buyerID',\n",
    "    'First Name':'firstName',\n",
    "    'Last Name':'lastName',\n",
    "    'Date Shipped':'dateShipped',\n",
    "    'Street 1':'street1',\n",
    "    'Street 2':'street2',\n",
    "    'Ship City':'city',\n",
    "    'Ship State':'state',\n",
    "    'Ship Zipcode':'zipCode',\n",
    "    'Ship Country':'country',\n",
    "    'Order Value':'orderValue',\n",
    "    'Coupon Code':'couponCode',\n",
    "    'Coupon Details':'details',\n",
    "    'Discount Amount':'discountAmount',\n",
    "    'Shipping Discount':'shippingDiscount',\n",
    "    'Shipping':'shipping',\n",
    "    'Sales Tax':'salesTax',\n",
    "    'Order Total':'orderTotal',\n",
    "    'Card Processing Fees':'fees',\n",
    "    'Order Net':'orderNet',\n",
    "    'Adjusted Order Total':'adjustedTotal',\n",
    "    'Adjusted Card Processing Fees':'adjustedFees',\n",
    "    'Adjusted Net Order Amount':'adjustedNet',\n",
    "    'Order Type':'orderType',\n",
    "    'Payment Type':'paymentType',\n",
    "    })\n",
    "except:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} ***ERROR: Unable to rename sold_orders_df columns\")\n",
    "    print(\"***ERROR: Unable to rename sold_orders_df columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buyers_df=sold_orders_df2[['orderID',\n",
    "'buyerID',\n",
    "'firstName',\n",
    "'lastName']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buyer_info_df=pd.merge(buyers_df,buyer_contact,on='orderID',how='outer')\n",
    "buyer_info_df=buyer_info_df.drop(['Name'],axis=1)\n",
    "buyer_info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buyer_info_df['record_date']=yesterday_full_date\n",
    "\n",
    "buyer_info_df = buyer_info_df.applymap(str)\n",
    "buyer_info_df.fillna(\"\", inplace=True)\n",
    "\n",
    "data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "data_collection_log.write(f\"\\n{datetime.now()} DF Complete- buyer_info_df\")\n",
    "print(\"DF Complete- buyer_info_df\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that records for the day have not already been added\n",
    "# Do the following if the dataframe is not empty\n",
    "if buyer_info_df.empty == False:\n",
    "    fb_db = \"buyers.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase buyer_info_df\")\n",
    "        print(\"***ERROR- Acess Firebase buyer_info_df\")\n",
    "        \n",
    "    df_tups = [(item.buyerID, item.orderID) for index, item in df_fb.iterrows()]\n",
    "    \n",
    "    ref = db.reference('buyers')\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    \n",
    "    # New record count\n",
    "    count=0\n",
    "    \n",
    "    for index, item in buyer_info_df.iterrows():\n",
    "        \n",
    "        # Create tuples from local df        \n",
    "        var_o=item.buyerID, item.orderID\n",
    "        \n",
    "        if var_o not in df_tups:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "\n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "\n",
    "            items=item.values.tolist()\n",
    "\n",
    "            new_val= \", \".join( repr(e) for e in items ) \n",
    "\n",
    "            new_val2=new_val.replace(\"'\",\"\")\n",
    "\n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/buyers.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{new_val2}\") \n",
    "            \n",
    "        else:\n",
    "            pass            \n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to buyers\")\n",
    "    print(f\"Firebase- {count} records added to buyers\")\n",
    "\n",
    "\n",
    "        \n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- buyer_info_df\")\n",
    "    print(\"DF EMPTY- buyer_info_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shipping_Addresses DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shipping_addresses_df=sold_orders_df2[['buyerID',\n",
    "'city',\n",
    "'country',\n",
    "'orderID',\n",
    "'state',\n",
    "'street1',\n",
    "'street2',\n",
    "'zipCode']]\n",
    "\n",
    "shipping_addresses_df = shipping_addresses_df.applymap(str)\n",
    "shipping_addresses_df.fillna(\"\", inplace=True)\n",
    "\n",
    "data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "data_collection_log.write(f\"\\n{datetime.now()} DF Complete- shipping_addresses_df\")\n",
    "print(\"DF Complete- shipping_addresses_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that records for the day have not already been added\n",
    "# Do the following if the dataframe is not empty\n",
    "if shipping_addresses_df.empty == False:\n",
    "    fb_db = \"shipping_addresses.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase shipping_addresses_df\")\n",
    "        print(\"***ERROR- Acess Firebase shipping_addresses_df\")\n",
    "        \n",
    "    df_tups = [(item.buyerID, item.orderID) for index, item in df_fb.iterrows()]\n",
    "    \n",
    "    ref = db.reference('shipping_addresses')\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    \n",
    "    # New record count\n",
    "    count=0\n",
    "    \n",
    "    for index, item in shipping_addresses_df.iterrows():\n",
    "        \n",
    "        # Create tuples from local df        \n",
    "        var_o=item.buyerID, item.orderID\n",
    "        \n",
    "        if var_o not in df_tups:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "\n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "\n",
    "            items=item.values.tolist()\n",
    "\n",
    "            new_val= \", \".join( repr(e) for e in items ) \n",
    "\n",
    "            new_val2=new_val.replace(\"'\",\"\")\n",
    "\n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/shipping_addresses.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{new_val2}\") \n",
    "            \n",
    "        else:\n",
    "            pass            \n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to shipping_addresses\")\n",
    "    print(f\"Firebase- {count} records added to shipping_addresses\")\n",
    "\n",
    "\n",
    "        \n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- shipping_addresses_df\")\n",
    "    print(\"DF EMPTY- shipping_addresses_df\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orders DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data frame from CSV\n",
    "orders_df_temp1=sold_orders_df2[['orderID',\n",
    "'orderDate',\n",
    "'buyerID']]\n",
    "\n",
    "#Only return open orders\n",
    "orders_df=pd.merge(orders_df_temp1,orders_df_temp2,on='orderID',how='outer')\n",
    "\n",
    "orders_df=orders_df[['orderID','orderDate','orderTime','shipByDate','buyerID','orderURL']]\n",
    "\n",
    "orders_df['orderDate'] = pd.to_datetime(orders_df['orderDate'], format='%m/%d/%y',errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "\n",
    "orders_df = orders_df.applymap(str)\n",
    "orders_df.fillna(\"\", inplace=True)\n",
    "\n",
    "data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "data_collection_log.write(f\"\\n{datetime.now()} DF Complete- orders_df\")\n",
    "print(\"DF Complete- orders_df\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that records for the day have not already been added\n",
    "# Do the following if the dataframe is not empty\n",
    "if orders_df.empty == False:\n",
    "    fb_db = \"orders.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase orders\")\n",
    "        print(\"***ERROR- Acess Firebase orders\")\n",
    "        \n",
    "    orderIDs_ = df_fb.orderID.values\n",
    "\n",
    "    ref = db.reference('orders')\n",
    "    \n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    # New record count\n",
    "    count=0\n",
    "    \n",
    "    for index, item in orders_df.iterrows():\n",
    "        if item.orderID not in orderIDs_:\n",
    "            #push\n",
    "            ref.push(item.to_dict()) \n",
    "            \n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "            \n",
    "            items=item.values.tolist()\n",
    "            \n",
    "            new_val= \", \".join( repr(e) for e in items ) \n",
    "            \n",
    "            new_val2=new_val.replace(\"'\",\"\")\n",
    "            \n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/orders.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{new_val2}\") \n",
    "            txt_file.close()            \n",
    "        \n",
    "        else:\n",
    "            pass            \n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to orders\")\n",
    "    print(f\"Firebase- {count} records added to orders\")\n",
    "\n",
    "\n",
    "        \n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- orders_df\")\n",
    "    print(\"DF EMPTY- orders_df\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order_shipped DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_shipped_df = sold_orders_df2[['orderID','dateShipped']]\n",
    "#delete rows that contain NaN/null - only want to import complete records\n",
    "orders_shipped_df2 = orders_shipped_df[~orders_shipped_df.dateShipped.str.contains(\"nan\")]\n",
    "orders_shipped_df3 = orders_shipped_df2.applymap(str)\n",
    "orders_shipped_df3.fillna(\"\", inplace=True)\n",
    "\n",
    "data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "data_collection_log.write(f\"\\n{datetime.now()} DF Complete- orders_shipped_df\")\n",
    "print(\"DF Complete- orders_shipped_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that records for the day have not already been added\n",
    "# Do the following if the dataframe is not empty\n",
    "if orders_shipped_df3.empty == False:\n",
    "    fb_db = \"order_shipped.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase order_shipped\")\n",
    "        print(\"***ERROR- Acess Firebase order_shipped\")\n",
    "        \n",
    "    df_tups = [(item.orderID, item.dateShipped) for index, item in df_fb.iterrows()]\n",
    "    \n",
    "    \n",
    "    ref = db.reference('order_shipped')\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    \n",
    "    # New record count\n",
    "    count=0\n",
    "    \n",
    "    for index, item in orders_shipped_df3.iterrows():\n",
    "        \n",
    "        # Create tuples from local df        \n",
    "        var_o=item.orderID, item.dateShipped\n",
    "        \n",
    "        if var_o not in df_tups:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "\n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "\n",
    "            items=item.values.tolist()\n",
    "\n",
    "            new_val= \", \".join( repr(e) for e in items ) \n",
    "\n",
    "            new_val2=new_val.replace(\"'\",\"\")\n",
    "\n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/order_shipped.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{new_val2}\") \n",
    "            txt_file.close()            \n",
    "            \n",
    "        else:\n",
    "            pass            \n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to order_shipped\")\n",
    "    print(f\"Firebase- {count} records added to order_shipped\")\n",
    "\n",
    "\n",
    "        \n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- orders_shipped_df3\")\n",
    "    print(\"DF EMPTY- orders_shipped_df3\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Order_pay df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order_payment_df_temp1=direct_checkout_payments_df[['Order ID','Gift Card Applied?']]\n",
    "order_payment_df_temp1=order_payment_df_temp1.rename(columns={'Order ID':'orderID','Gift Card Applied?':'giftCard'})\n",
    "order_payment_df_temp2=sold_orders_df2[['orderID',\n",
    "'orderValue',\n",
    "'couponCode',\n",
    "'discountAmount',\n",
    "'shippingDiscount',\n",
    "'shipping',\n",
    "'salesTax',\n",
    "'orderTotal',\n",
    "'fees',\n",
    "'orderNet',\n",
    "'orderType',\n",
    "'paymentType'\n",
    "]]\n",
    "# Join data frames on orderID\n",
    "order_payment_df=pd.merge(order_payment_df_temp2,order_payment_df_temp1,on='orderID',how='outer')\n",
    "\n",
    "order_payment_df = order_payment_df.applymap(str)\n",
    "order_payment_df.fillna(\"\", inplace=True)\n",
    "\n",
    "data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "data_collection_log.write(f\"\\n{datetime.now()} DF Complete- order_payment_df\")\n",
    "print(\"DF Complete- order_payment_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only push new records\n",
    "order_pay_db = \"order_pay.json\"\n",
    "r = requests.get(config.databaseURL + order_pay_db)\n",
    "r = r.json()\n",
    "\n",
    "if r:\n",
    "    data = [r[i] for i in r]\n",
    "    df_fb = pd.DataFrame.from_dict(data, orient='columns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that records for the day have not already been added\n",
    "# Do the following if the dataframe is not empty\n",
    "if order_payment_df.empty == False:\n",
    "    fb_db = \"order_pay.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase order_pay\")\n",
    "        print(\"***ERROR- Acess Firebase order_pay\")\n",
    "        \n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    \n",
    "    # New record count\n",
    "    count=0\n",
    "    \n",
    "    orderIDs_ = df_fb.orderID.values\n",
    "\n",
    "    ref = db.reference('order_pay')\n",
    "\n",
    "    for index, item in order_payment_df.iterrows():\n",
    "        if item.orderID not in orderIDs_:\n",
    "            #push\n",
    "            ref.push(item.to_dict()) \n",
    "    \n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "            \n",
    "            items=item.values.tolist()\n",
    "            \n",
    "            new_val= \", \".join( repr(e) for e in items ) \n",
    "            \n",
    "            new_val2=new_val.replace(\"'\",\"\")\n",
    "            \n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/order_pay.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{new_val2}\") \n",
    "            \n",
    "        else:\n",
    "            pass            \n",
    "    \n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} Firebase- {count} records added to order_pay\")\n",
    "    print(f\"Firebase- {count} records added to order_pay\")\n",
    "\n",
    "\n",
    "        \n",
    "else:\n",
    "    data_collection_log= open(f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/logs/{yesterday_full_date}_data_collection_log.txt\",\"a\")\n",
    "    data_collection_log.write(f\"\\n{datetime.now()} DF EMPTY- order_payment_df\")\n",
    "    print(\"DF EMPTY- order_payment_df\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# eRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://erank.com/login'\n",
    "# Navigate to login page\n",
    "driver.get(url)\n",
    "html=driver.page_source\n",
    "\n",
    "# Populate sign in fields\n",
    "emailElem = driver.find_element_by_id('signin-email')\n",
    "emailElem.send_keys(config.erank_email)\n",
    "passwordElem = driver.find_element_by_id('signin-password')\n",
    "passwordElem.send_keys(config.erank_password)\n",
    "# Submit sign in information\n",
    "passwordElem.submit()\n",
    "sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shop Stats DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://erank.com/login/refreshing'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://erank.com/top-sellers/lookup?shop=jetchcreations'\n",
    "\n",
    "driver.get(url)\n",
    "sleep(2)\n",
    "html=driver.page_source\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#Scrape shop stats\n",
    "sections=soup.find_all('div',class_='col-lg-4 col-md-6 col-sm-4 col-xs-12 m-b-10 p-l-0')\n",
    "info_type=[]\n",
    "for section in sections:\n",
    "    text=section.find('p',class_='m-t-5').text\n",
    "    text=text.replace('\\n\\n\\n\\n',\"\")\n",
    "    info_type.append(text)\n",
    "\n",
    "#Transform shop stats to data frame\n",
    "info_type = [word.strip() for word in info_type]\n",
    "\n",
    "results=[]\n",
    "category=[]\n",
    "value=[]\n",
    "\n",
    "for string in info_type:\n",
    "    result = [x.strip() for x in string.split('  ')]   \n",
    "    results.append(result)\n",
    "\n",
    "for l in results:\n",
    "    category.append(l[0])\n",
    "    value.append(l[-1])\n",
    "\n",
    "\n",
    "erank_shop_stats = pd.DataFrame(columns=category)\n",
    "\n",
    "erank_shop_stats.loc[len(erank_shop_stats), :] = value\n",
    "\n",
    "erank_shop_stats['record_date']=yesterday_full_date\n",
    "\n",
    "\n",
    "shop_stats_fix=erank_shop_stats.rename(columns={'Total Sales':'sales',\n",
    "'Sales Rank (Global)':'salesRankWW',\n",
    "'Sales Rank (National)':'salesRankNAT',\n",
    "'Shop Age':'shopAge',\n",
    "'Avg. Sales/Day':'avgSales',\n",
    "'Category':'category'})\n",
    "\n",
    "shop_stats_fix=shop_stats_fix[['record_date','avgSales','category',\n",
    "                                'salesRankWW','salesRankNAT',\n",
    "                                'shopAge','sales']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_stats_fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shop_stats_fp = \"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/eRank_ShopStats.csv\"\n",
    "\n",
    "# Create or append to csv\n",
    "if not os.path.isfile(shop_stats_fp):\n",
    "    shop_stats_fix.to_csv(shop_stats_fp, header='column_names')\n",
    "else: # else it exists so append without writing the header\n",
    "    shop_stats_fix.to_csv(shop_stats_fp, mode='a', header=False, index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Push record to database\n",
    "ref = db.reference('shop_stats')\n",
    "shop_stats_fix.fillna(\"\", inplace=True)\n",
    "[ref.push(item.to_dict()) for index, item in shop_stats_fix.iterrows()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotted On Etsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://erank.com/spotted-on-etsy'\n",
    "\n",
    "driver.get(url)\n",
    "sleep(2)\n",
    "html=driver.page_source\n",
    "soup=BeautifulSoup(html,'lxml')\n",
    "\n",
    "table=soup.find('table',class_='table table-striped dataTable no-footer')\n",
    "\n",
    "tr_data=table.find_all('tr')\n",
    "\n",
    "table_info=[]\n",
    "listing_ids=[]\n",
    "listing_id2=[]\n",
    "listing_id3=[]\n",
    "search_terms=[]\n",
    "page=[]\n",
    "position=[]\n",
    "rank=[]\n",
    "timestamp=[]\n",
    "\n",
    "for tr in tr_data[1:]:\n",
    "    td = tr.find_all('td')\n",
    "    row = [tr.text for tr in td]\n",
    "    listing_id2.append(row[2])  \n",
    "    search_terms.append(row[3])\n",
    "    page.append(row[4])\n",
    "    positions = row[5].replace('\\n', ' ').strip()\n",
    "    position.append(positions)\n",
    "    ranks = row[6].replace('\\n', ' ').strip()\n",
    "    rank.append(ranks)\n",
    "    timestamps = row[7].replace('\\n', ' ').strip()\n",
    "    timestamp.append(timestamps)\n",
    "\n",
    "for item in listing_id2:\n",
    "    listing_id = re.split(r'[()]', item)\n",
    "    listing_ids.append(listing_id[1])\n",
    "\n",
    "    \n",
    "spotted_etsy_df=pd.DataFrame({'listingID':listing_ids,\n",
    "'searchTerms':search_terms,\n",
    "'page':page,\n",
    "'position':position,\n",
    "'rank':rank,\n",
    "'timestamp':timestamp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotted_etsy_fp=\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/eRank_SpottedOnEtsy.csv\"\n",
    "\n",
    "\n",
    "# Create or append to csv\n",
    "if not os.path.isfile(spotted_etsy_fp):\n",
    "    spotted_etsy_df.to_csv(spotted_etsy_fp, header='column_names')\n",
    "else: # else it exists so append without writing the header\n",
    "    spotted_etsy_df.to_csv(spotted_etsy_fp, mode='a', header=False,index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = db.reference('spotted_on_etsy')\n",
    "spotted_etsy_df.fillna(\"\", inplace=True)\n",
    "[ref.push(item.to_dict()) for index, item in spotted_etsy_df.iterrows()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEO_Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://erank.com/listings/grades'\n",
    "driver.get(url)\n",
    "sleep(2)\n",
    "html=driver.page_source\n",
    "\n",
    "#Download CSV\n",
    "download=driver.find_element_by_xpath('//*[@id=\"listing-table_wrapper\"]/div/div[2]/div/a[2]')\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(download).click().perform()\n",
    "sleep(5)\n",
    "\n",
    "SEO_grades=\"/Users/jessicaetchechury/Downloads/eRank - Grades.csv\"\n",
    "SEO_grades=pd.read_csv(SEO_grades)\n",
    "\n",
    "SEO_grades['record_date']=yesterday_full_date\n",
    "\n",
    "SEO_grades.drop(columns=['MainImage','#'],axis=1,inplace=True)\n",
    "SEO_grades['ListingTitle'] = SEO_grades['ListingTitle'].str.split(': ').str[1]\n",
    "SEO_grades['ListingTitle'] = SEO_grades['ListingTitle'].str.split('\\ ').str[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEOGrades_fp=f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/eRank_SEOGrades.csv\"\n",
    "\n",
    " # Create or append to csv\n",
    "if not os.path.isfile(SEOGrades_fp):\n",
    "    SEO_grades.to_csv(SEOGrades_fp, header='column_names')\n",
    "else: # else it exists so append without writing the header\n",
    "    SEO_grades.to_csv(SEOGrades_fp, mode='a', header=False,index=False)\n",
    "\n",
    "os.remove(\"/Users/jessicaetchechury/Downloads/eRank - Grades.csv\")\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEO_grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = db.reference('seo_ratings')\n",
    "SEO_grades.fillna(\"\", inplace=True)\n",
    "[ref.push(item.to_dict()) for index, item in SEO_grades.iterrows()]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Listing_Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://erank.com/listings/details'\n",
    "driver.get(url)\n",
    "sleep(2)\n",
    "html=driver.page_source\n",
    "\n",
    "#Download CSV\n",
    "download=driver.find_element_by_xpath('//*[@id=\"listing-table_wrapper\"]/div/div[2]/div/a[2]')\n",
    "actions = ActionChains(driver)\n",
    "actions.move_to_element(download).click().perform()\n",
    "sleep(5)\n",
    "\n",
    "details_fp=\"/Users/jessicaetchechury/Downloads/eRank - Details.csv\"\n",
    "listing_details_df=pd.read_csv(details_fp)\n",
    "\n",
    "listing_details_df.drop(columns=['MainImage',\"ListingTitle\",'#'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ListingID</th>\n",
       "      <th>SKU</th>\n",
       "      <th>TagCount</th>\n",
       "      <th>ImageCount</th>\n",
       "      <th>OriginallyCreated</th>\n",
       "      <th>LastUpdated</th>\n",
       "      <th>TotalViews</th>\n",
       "      <th>DailyViews</th>\n",
       "      <th>TotalHearts</th>\n",
       "      <th>Hearts per View</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>685451744</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-04-16</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>50</td>\n",
       "      <td>0.4</td>\n",
       "      <td>9</td>\n",
       "      <td>18.0%</td>\n",
       "      <td>49.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>703387331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-05-02</td>\n",
       "      <td>2019-07-04</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>18.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>688443618</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-04-28</td>\n",
       "      <td>2019-07-04</td>\n",
       "      <td>18</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1%</td>\n",
       "      <td>46.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>701341356</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>17</td>\n",
       "      <td>0.3</td>\n",
       "      <td>8</td>\n",
       "      <td>47.1%</td>\n",
       "      <td>12.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>701210678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>2019-07-04</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0%</td>\n",
       "      <td>20.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>693933847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>2019-07-04</td>\n",
       "      <td>17</td>\n",
       "      <td>0.1</td>\n",
       "      <td>4</td>\n",
       "      <td>23.5%</td>\n",
       "      <td>24.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>701344590</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2019-06-18</td>\n",
       "      <td>2019-07-16</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>4</td>\n",
       "      <td>50.0%</td>\n",
       "      <td>30.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>680079806</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>2019-07-04</td>\n",
       "      <td>51</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6</td>\n",
       "      <td>11.8%</td>\n",
       "      <td>30.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>722901675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-20</td>\n",
       "      <td>2019-07-23</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>693930997</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>159</td>\n",
       "      <td>1.2</td>\n",
       "      <td>21</td>\n",
       "      <td>13.2%</td>\n",
       "      <td>25.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ListingID  SKU  TagCount  ImageCount OriginallyCreated LastUpdated  \\\n",
       "16  685451744  NaN        12           1        2019-04-16  2019-07-17   \n",
       "11  703387331  NaN        10           7        2019-05-02  2019-07-04   \n",
       "5   688443618  NaN         6          10        2019-04-28  2019-07-04   \n",
       "22  701341356  NaN        10           2        2019-06-18  2019-07-17   \n",
       "9   701210678  NaN        10           4        2019-06-18  2019-07-04   \n",
       "7   693933847  NaN        13           5        2019-03-26  2019-07-04   \n",
       "15  701344590  NaN        10           4        2019-06-18  2019-07-16   \n",
       "1   680079806  NaN        12           5        2019-03-26  2019-07-04   \n",
       "30  722901675  NaN         0           1        2019-07-20  2019-07-23   \n",
       "18  693930997  NaN        13           5        2019-03-26  2019-07-17   \n",
       "\n",
       "    TotalViews  DailyViews  TotalHearts Hearts per View  Price  \n",
       "16          50         0.4            9           18.0%  49.99  \n",
       "11          10         0.1            0            0.0%  18.50  \n",
       "5           18         0.2            2           11.1%  46.00  \n",
       "22          17         0.3            8           47.1%  12.50  \n",
       "9            4         0.1            0            0.0%  20.50  \n",
       "7           17         0.1            4           23.5%  24.99  \n",
       "15           8         0.2            4           50.0%  30.00  \n",
       "1           51         0.4            6           11.8%  30.99  \n",
       "30           0         0.0            0             NaN  59.00  \n",
       "18         159         1.2           21           13.2%  25.99  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_details_df.sample(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_details_df=listing_details_df[['ListingID','OriginallyCreated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ListingID</th>\n",
       "      <th>OriginallyCreated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>680077296</td>\n",
       "      <td>2019-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>680079806</td>\n",
       "      <td>2019-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>680082346</td>\n",
       "      <td>2019-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>680084324</td>\n",
       "      <td>2019-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>680085112</td>\n",
       "      <td>2019-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>688443618</td>\n",
       "      <td>2019-04-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>691796412</td>\n",
       "      <td>2019-05-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>693933847</td>\n",
       "      <td>2019-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>701202082</td>\n",
       "      <td>2019-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>701210678</td>\n",
       "      <td>2019-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>702303569</td>\n",
       "      <td>2019-04-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>703387331</td>\n",
       "      <td>2019-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>704569159</td>\n",
       "      <td>2019-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>687898920</td>\n",
       "      <td>2019-04-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>688465922</td>\n",
       "      <td>2019-04-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>701344590</td>\n",
       "      <td>2019-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>685451744</td>\n",
       "      <td>2019-04-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>690717354</td>\n",
       "      <td>2019-05-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>693930997</td>\n",
       "      <td>2019-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>693947901</td>\n",
       "      <td>2019-03-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>700377146</td>\n",
       "      <td>2019-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>700382982</td>\n",
       "      <td>2019-06-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>701341356</td>\n",
       "      <td>2019-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>706002567</td>\n",
       "      <td>2019-05-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>721879701</td>\n",
       "      <td>2019-07-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>721881161</td>\n",
       "      <td>2019-07-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>680069172</td>\n",
       "      <td>2019-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>680071910</td>\n",
       "      <td>2019-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>680073964</td>\n",
       "      <td>2019-03-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>701339360</td>\n",
       "      <td>2019-06-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>722901675</td>\n",
       "      <td>2019-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>680064082</td>\n",
       "      <td>2019-03-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ListingID OriginallyCreated\n",
       "0   680077296        2019-03-26\n",
       "1   680079806        2019-03-26\n",
       "2   680082346        2019-03-26\n",
       "3   680084324        2019-03-26\n",
       "4   680085112        2019-03-27\n",
       "5   688443618        2019-04-28\n",
       "6   691796412        2019-05-11\n",
       "7   693933847        2019-03-26\n",
       "8   701202082        2019-06-18\n",
       "9   701210678        2019-06-18\n",
       "10  702303569        2019-04-28\n",
       "11  703387331        2019-05-02\n",
       "12  704569159        2019-05-07\n",
       "13  687898920        2019-04-26\n",
       "14  688465922        2019-04-28\n",
       "15  701344590        2019-06-18\n",
       "16  685451744        2019-04-16\n",
       "17  690717354        2019-05-07\n",
       "18  693930997        2019-03-26\n",
       "19  693947901        2019-03-27\n",
       "20  700377146        2019-06-14\n",
       "21  700382982        2019-06-14\n",
       "22  701341356        2019-06-18\n",
       "23  706002567        2019-05-13\n",
       "24  721879701        2019-07-16\n",
       "25  721881161        2019-07-16\n",
       "26  680069172        2019-03-26\n",
       "27  680071910        2019-03-26\n",
       "28  680073964        2019-03-26\n",
       "29  701339360        2019-06-18\n",
       "30  722901675        2019-07-20\n",
       "31  680064082        2019-03-26"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listing_details_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<firebase_admin.db.Reference at 0x11636c8d0>,\n",
       " <firebase_admin.db.Reference at 0x1035b4a20>,\n",
       " <firebase_admin.db.Reference at 0x1179de748>,\n",
       " <firebase_admin.db.Reference at 0x11636c898>,\n",
       " <firebase_admin.db.Reference at 0x1035e0278>,\n",
       " <firebase_admin.db.Reference at 0x116874a20>,\n",
       " <firebase_admin.db.Reference at 0x1165896d8>,\n",
       " <firebase_admin.db.Reference at 0x116574e80>,\n",
       " <firebase_admin.db.Reference at 0x116574cc0>,\n",
       " <firebase_admin.db.Reference at 0x116574f28>,\n",
       " <firebase_admin.db.Reference at 0x112c20390>,\n",
       " <firebase_admin.db.Reference at 0x1168aef28>,\n",
       " <firebase_admin.db.Reference at 0x1168aeb00>,\n",
       " <firebase_admin.db.Reference at 0x1168aecc0>,\n",
       " <firebase_admin.db.Reference at 0x1168ae470>,\n",
       " <firebase_admin.db.Reference at 0x1168aee48>,\n",
       " <firebase_admin.db.Reference at 0x1168aebe0>,\n",
       " <firebase_admin.db.Reference at 0x1168ae860>,\n",
       " <firebase_admin.db.Reference at 0x1168ae1d0>,\n",
       " <firebase_admin.db.Reference at 0x1168ae390>,\n",
       " <firebase_admin.db.Reference at 0x1168aef60>,\n",
       " <firebase_admin.db.Reference at 0x1168aee80>,\n",
       " <firebase_admin.db.Reference at 0x1168aea20>,\n",
       " <firebase_admin.db.Reference at 0x1168ae4e0>,\n",
       " <firebase_admin.db.Reference at 0x1168aef98>,\n",
       " <firebase_admin.db.Reference at 0x116574be0>,\n",
       " <firebase_admin.db.Reference at 0x1168ae0b8>,\n",
       " <firebase_admin.db.Reference at 0x1168ae940>,\n",
       " <firebase_admin.db.Reference at 0x1168aeda0>,\n",
       " <firebase_admin.db.Reference at 0x1168ae780>,\n",
       " <firebase_admin.db.Reference at 0x1168ae6a0>,\n",
       " <firebase_admin.db.Reference at 0x1168ae5c0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = db.reference('listing_creation_dates')\n",
    "listing_details_df.fillna(\"\", inplace=True)\n",
    "[ref.push(item.to_dict()) for index, item in listing_details_df.iterrows()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df to list\n",
    "items=listing_details_df.values.tolist()\n",
    "\n",
    "# Loop through each item in list\n",
    "for item in items:\n",
    "    # Remove brackets form list and write to text file\n",
    "    new_val= \", \".join( repr(e) for e in item ) \n",
    "\n",
    "    txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/listing_creation.txt\",\"a\")\n",
    "    txt_file.write(f\"\\n{new_val}\") \n",
    "    txt_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "details_fp=\"/Users/jessicaetchechury/Downloads/eRank - Details (1).csv\"\n",
    "listing_details_df=pd.read_csv(details_fp)\n",
    "\n",
    "listing_details_df.drop(columns=['MainImage',\"ListingTitle\",'#'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "listing_details_df.head()\n",
    "listing_details_df=listing_details_df[['ListingID','OriginallyCreated']]\n",
    "listing_details_df = listing_details_df.applymap(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "685744834, 2019-04-17\n",
      "712150418, 2019-08-02\n",
      "712179258, 2019-08-02\n",
      "721874971, 2019-07-16\n",
      "707973152, 2019-07-16\n"
     ]
    }
   ],
   "source": [
    "if listing_details_df.empty == False:\n",
    "    fb_db = \"listing_creation_dates.json\"\n",
    "    r = requests.get(config.databaseURL + fb_db)\n",
    "    r = r.json()\n",
    "\n",
    "    if r:\n",
    "        data = [r[i] for i in r]\n",
    "        df_fb = pd.DataFrame.from_dict(data, orient='columns')\n",
    "        df_fb = df_fb.applymap(str)\n",
    "    else:\n",
    "        data_collection_log = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/DataCollection/data_collection_log.txt\",\"a\")\n",
    "        data_collection_log.write(f\"\\n{datetime.now()} ***ERROR- Acess Firebase listing_creation_dates\")\n",
    "        print(\"***ERROR- Acess Firebase listing_creation_dates\")\n",
    "        \n",
    "    df_tups = [(item.ListingID,item.OriginallyCreated) for index, item in df_fb.iterrows()]\n",
    "    \n",
    "    ref = db.reference('listing_creation_dates')\n",
    "    # Compare tuples from Firebase database and tuples from local df.  Only add tuples that do not already exist in Firebase database\n",
    "    \n",
    "    # New record count\n",
    "    count=0\n",
    "    \n",
    "    for index, item in listing_details_df.iterrows():\n",
    "        \n",
    "        # Create tuples from local df        \n",
    "        var_o=item.ListingID,item.OriginallyCreated\n",
    "        \n",
    "        if var_o not in df_tups:\n",
    "            # Push item to db\n",
    "            ref.push(item.to_dict()) \n",
    "            \n",
    "            # Add to new record count\n",
    "            count += 1\n",
    "            \n",
    "            items=item.values.tolist()\n",
    "            \n",
    "            new_val= \", \".join( repr(e) for e in items ) \n",
    "            \n",
    "            new_val2=new_val.replace(\"'\",\"\")\n",
    "            \n",
    "            txt_file = open(\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/listing_creation.txt\",\"a\")\n",
    "            txt_file.write(f\"\\n{new_val2}\") \n",
    "            print(new_val2)\n",
    "        else:\n",
    "            pass            \n",
    "else:\n",
    "   print(\"error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competitor Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If weekday is Monday, run script to scrape competitor sale data\n",
    "\n",
    "weekday = datetime.today().weekday()\n",
    "\n",
    "if weekday == 0:\n",
    "\n",
    "    url='https://erank.com/competitor-sales'\n",
    "    driver.get(url)\n",
    "    sleep(2)\n",
    "    html=driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Click on download button\n",
    "    download_button=driver.find_element_by_xpath('//*[@id=\"table129344_wrapper\"]/div/div[2]/div/a[2]')\n",
    "    actions = ActionChains(driver)\n",
    "    actions.move_to_element(download_button).click().perform()\n",
    "    sleep(2)\n",
    "\n",
    "    competitor_sales_fp =\"/Users/jessicaetchechury/Downloads/eRank - Competitor Sales.csv\"\n",
    "    competitor_sales=pd.read_csv(competitor_sales_fp)\n",
    "\n",
    "    sleep(2)\n",
    "    competitors = list(competitor_sales['Shop'])\n",
    "\n",
    "    comp_sales_daily = competitor_sales.drop(competitor_sales.iloc[:,11:14],axis=1)\n",
    "    comp_sales_daily.drop(comp_sales_daily.columns[[0,2,3,-1]],axis=1,inplace=True)\n",
    "\n",
    "    # Get df column values\n",
    "    comp_sales_daily_columns = comp_sales_daily.columns.get_values()\n",
    "\n",
    "    # Turn column values to list\n",
    "    comp_sales_daily_columns=comp_sales_daily_columns.tolist()\n",
    "\n",
    "    # Identify IDs for melt\n",
    "    id_vars=['Shop']\n",
    "\n",
    "    # Identify values for melt\n",
    "    for item in id_vars:\n",
    "        comp_sales_daily_columns.remove(item)\n",
    "\n",
    "    # Melt df \n",
    "    comp_sales_daily2=pd.melt(comp_sales_daily, id_vars=id_vars, value_vars=comp_sales_daily_columns)\n",
    "\n",
    "    # Add year and change str to datetime\n",
    "    comp_sales_daily2['date'] = yesterday_year + comp_sales_daily2['variable'].astype(str)\n",
    "    comp_sales_daily2['date']= pd.to_datetime(comp_sales_daily2['date'], format=\"%Y%a%d-%b\")\n",
    "\n",
    "    # Drop column no longer needed \n",
    "    comp_sales_daily2=comp_sales_daily2.drop(['variable'],axis=1)\n",
    "\n",
    "    # Rename value column to sales\n",
    "    comp_sales_daily2=comp_sales_daily2.rename(columns={'value':'sales'})\n",
    "\n",
    "    comp_sales_daily2['week'] = (comp_sales_daily2['date'] + pd.DateOffset(days=1)).dt.week\n",
    "    \n",
    "    cur_week_no=comp_sales_daily2.iloc[0]['week']\n",
    "\n",
    "    comp_sales_sum=competitor_sales.drop(competitor_sales.iloc[:,4:12],axis=1)\n",
    "    comp_sales_sum.drop(comp_sales_sum.columns[[0,2]],axis=1,inplace=True)\n",
    "\n",
    "    comp_sales_sum=comp_sales_sum.rename(columns={'Week':'weeklySales'})\n",
    "\n",
    "    comp_sales_sum['week']=cur_week_no\n",
    "    \n",
    "    \n",
    "    comp_sales_sum_fp = \"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/eRank_CompetitorSalesSummary.csv\"\n",
    "\n",
    "    #Create or append to csv\n",
    "    if not os.path.isfile(comp_sales_sum_fp):\n",
    "        comp_sales_sum.to_csv(comp_sales_sum_fp, header='column_names')\n",
    "    else: # else it exists so append without writing the header\n",
    "        comp_sales_sum.to_csv(comp_sales_sum_fp, mode='a', header=False, index=False)\n",
    "    \n",
    "    \n",
    "    comp_sales_daily_fp = \"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/eRank_CompetitorSalesDaily.csv\"                         \n",
    "                              \n",
    "    # Create or append to csv\n",
    "    if not os.path.isfile(comp_sales_daily_fp):\n",
    "        comp_sales_daily2.to_csv(comp_sales_daily_fp, header='column_names')\n",
    "    else: # else it exists so append without writing the header\n",
    "        comp_sales_daily2.to_csv(comp_sales_daily_fp, mode='a', header=False, index=False)\n",
    "    \n",
    "    os.remove(\"/Users/jessicaetchechury/Downloads/eRank - Competitor Sales.csv\")\n",
    "    \n",
    "    comp_sales_daily2['date'] = comp_sales_daily2['date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "    #Append to database\n",
    "    ref = db.reference('comp_sales_daily')\n",
    "    comp_sales_daily2.fillna(\"\", inplace=True)\n",
    "    [ref.push(item.to_dict()) for index, item in comp_sales_daily2.iterrows()]\n",
    "    \n",
    "    ref = db.reference('comp_sales_summary')\n",
    "    comp_sales_sum.fillna(\"\", inplace=True)\n",
    "    [ref.push(item.to_dict()) for index, item in comp_sales_sum.iterrows()]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competitor Listings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if weekday == 0:\n",
    "    url='https://erank.com/competitor-listings'\n",
    "\n",
    "    driver.get(url)\n",
    "    sleep(2)\n",
    "    html=driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    for competitor in competitors:\n",
    "        if competitor != 'jetchcreations':\n",
    "            select = Select(driver.find_element_by_id('list'))\n",
    "            select.select_by_value('/competitor-listings/'+competitor)\n",
    "            sleep(2)\n",
    "\n",
    "            go_button=driver.find_element_by_xpath('//*[@id=\"er-page-content-wrapper\"]/div/div/div/div/div[1]/div[5]/div/table/tbody/tr/td[3]/form/button')\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(go_button).click().perform()\n",
    "            sleep(5)\n",
    "\n",
    "            html=driver.page_source\n",
    "\n",
    "            download_button=driver.find_element_by_xpath('//*[@id=\"listing-table_wrapper\"]/div/div[2]/div/a[2]')\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(download_button).click().perform()\n",
    "            sleep(2)\n",
    "\n",
    "            #read in save csv\n",
    "            competitor_listings_fp=\"/Users/jessicaetchechury/Downloads/eRank - Competitor Listings.csv\"\n",
    "            competitor_listings=pd.read_csv(competitor_listings_fp)\n",
    "\n",
    "            #drop Image column\n",
    "            competitor_listings.drop(competitor_listings.columns[[0]],axis=1,inplace=True)\n",
    "\n",
    "            competitor_listings['record_date']=today_full_date\n",
    "\n",
    "            competitor_listings['Shop']=competitor\n",
    "\n",
    "            competitor_listings_fp=f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/eRank_CompetitorListings.csv\"\n",
    "\n",
    "            # Create or append to csv\n",
    "            if not os.path.isfile(competitor_listings_fp):\n",
    "                competitor_listings.to_csv(competitor_listings_fp, header='column_names')\n",
    "            else: # else it exists so append without writing the header\n",
    "                competitor_listings.to_csv(competitor_listings_fp, mode='a', header=False)\n",
    "\n",
    "            os.remove(\"/Users/jessicaetchechury/Downloads/eRank - Competitor Listings.csv\")\n",
    "            \n",
    "            competitor_listings['record_date'] = competitor_listings['record_date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "            ref = db.reference('comp_listings')\n",
    "            competitor_listings.fillna(\"\", inplace=True)\n",
    "            [ref.push(item.to_dict()) for index, item in competitor_listings.iterrows()]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competitor Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if weekday == 0:\n",
    "\n",
    "    url='https://erank.com/competitor-tags'\n",
    "\n",
    "    driver.get(url)\n",
    "    sleep(2)\n",
    "    html=driver.page_source\n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    for competitor in competitors:\n",
    "        if competitor != 'jetchcreations':\n",
    "            select = Select(driver.find_element_by_id('list'))\n",
    "            select.select_by_value('/competitor-tags/'+competitor)\n",
    "            sleep(2)\n",
    "\n",
    "            go_button=driver.find_element_by_xpath('//*[@id=\"er-page-content-wrapper\"]/div/div/div/div/div[1]/div[5]/div/table/tbody/tr/td[3]/form/button')\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(go_button).click().perform()\n",
    "            sleep(7)\n",
    "\n",
    "            html=driver.page_source\n",
    "\n",
    "            download_button=driver.find_element_by_xpath('//*[@id=\"dataTable9901_wrapper\"]/div/div[2]/div/a[2]')\n",
    "            actions = ActionChains(driver)\n",
    "            actions.move_to_element(download_button).click().perform()\n",
    "            sleep(2)\n",
    "\n",
    "            #read in save csv\n",
    "            competitor_tags_fp=\"/Users/jessicaetchechury/Downloads/eRank - Competitor Tagss.csv\"\n",
    "            competitor_tags=pd.read_csv(competitor_tags_fp)\n",
    "\n",
    "\n",
    "            competitor_tags['record_date']=today_full_date\n",
    "\n",
    "            competitor_tags['Shop']=competitor\n",
    "\n",
    "            competitor_tags_fp=f\"/Users/jessicaetchechury/Desktop/JEtchCreationsDashboard/Data/eRank_CompetitorListings.csv\"\n",
    "\n",
    "            # Create or append to csv\n",
    "            if not os.path.isfile(competitor_tags_fp):\n",
    "                competitor_tags.to_csv(competitor_tags_fp, header='column_names')\n",
    "            else: # else it exists so append without writing the header\n",
    "                competitor_tags.to_csv(competitor_tags_fp, mode='a', header=False)\n",
    "\n",
    "            os.remove(\"/Users/jessicaetchechury/Downloads/eRank - Competitor Tags.csv\")\n",
    "            \n",
    "            competitor_tags['record_date'] = competitor_tags['record_date'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "            ref = db.reference('comp_tags')\n",
    "            competitor_tags.fillna(\"\", inplace=True)\n",
    "            [ref.push(item.to_dict()) for index, item in competitor_tags.iterrows()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
